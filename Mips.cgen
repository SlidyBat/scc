arch Mips 32

#define REG_ZERO 0
#define REG_AT   1
#define REG_V(i) (2 + (i))
#define REG_A(i) (4 + (i))
#define REG_T(i) (((i) >= 8) ? (16 + (i)) : (8 + (i)))
#define REG_S(i) (16 + (i))
#define REG_K(i) (26 + (i))
#define REG_GP   28
#define REG_SP   29
#define REG_FP   30
#define REG_RA   31

#define REG_LO   32
#define REG_HI   33

#define SYMREG_ZERO SYMREG_NATIVE_REG(REG_ZERO)
#define SYMREG_LO SYMREG_NATIVE_REG(REG_LO)
#define SYMREG_HI SYMREG_NATIVE_REG(REG_HI)

registerclass default IREG(8,16,32)
registerclass INTEGER_RETURN_VALUE(8,16,32) fixed { REG_V(0) } : IREG
registerclass INTEGER_RETURN_VALUE_HIGH(32) fixed { REG_V(1) } : IREG
registerclass SYSCALL_RETURN(8,16,32) fixed { REG_V(0) } : IREG
registerclass SYSCALL_RETURN_HIGH(32) fixed { REG_V(1) } : IREG
registerclass LO(32) fixed { REG_LO }
registerclass HI(32) fixed { REG_HI }
largeregisterclass IREG64(64) IREG IREG
largeregisterclass INTEGER_RETURN_VALUE_64(64) INTEGER_RETURN_VALUE INTEGER_RETURN_VALUE_HIGH
largeregisterclass SYSCALL_RETURN_64(64) SYSCALL_RETURN SYSCALL_RETURN_HIGH
largeregisterclass LO_HI(64) LO HI
tempregisterclass IRESULT(8,16,32) IREG

registerclass INTEGER_PARAM_0(8,16,32) fixed { REG_A(0) } : IREG
registerclass INTEGER_PARAM_1(8,16,32) fixed { REG_A(1) } : IREG
registerclass INTEGER_PARAM_2(8,16,32) fixed { REG_A(2) } : IREG
registerclass INTEGER_PARAM_3(8,16,32) fixed { REG_A(3) } : IREG

registerclass SYSCALL_NUM(32) fixed { REG_V(0) } : IREG
registerclass SYSCALL_ERROR_FLAG(32) fixed { REG_A(3) } : IREG
registerclass SYSCALL_PARAM_0(8,16,32) fixed { REG_A(0) } : IREG
registerclass SYSCALL_PARAM_1(8,16,32) fixed { REG_A(1) } : IREG
registerclass SYSCALL_PARAM_2(8,16,32) fixed { REG_A(2) } : IREG
registerclass SYSCALL_PARAM_3(8,16,32) fixed { REG_A(3) } : IREG

immediateclass IMM16
{
	if (value < -0x8000)
		return false;
	if (value >= 0x8000)
		return false;
	return true;
}

immediateclass IMM16NEG
{
	if (value <= -0x8000)
		return false;
	if (value > 0x8000)
		return false;
	return true;
}

immediateclass IMM16M1
{
	if (value <= -0x8000)
		return false;
	if (value >= 0x8000)
		return false;
	return true;
}

immediateclass IMM16M4
{
	if (value < -0x8000)
		return false;
	if (value >= (0x8000 - 4))
		return false;
	return true;
}

immediateclass IMM16U
{
	if (value < 0)
		return false;
	if (value >= 0x10000)
		return false;
	return true;
}

immediateclass ZERO  { return value == 0; }

special SYMREG_SP { REG_SP }
special SYMREG_BP { REG_FP }
special SYMREG_LR { REG_RA }

callersaved { REG_AT, REG_V(0), REG_V(1), REG_A(0), REG_A(1), REG_A(2), REG_A(3), REG_T(0), REG_T(1), REG_T(2), REG_T(3),
	REG_T(4), REG_T(5), REG_T(6), REG_T(7), REG_T(8), REG_T(9) }
calleesaved { REG_S(0), REG_S(1), REG_S(2), REG_S(3), REG_S(4), REG_S(5), REG_S(6), REG_S(7) }

encoding R { op:6, rs:5, rt:5, rd:5, sh:5, f:6 }
encoding I { op:6, rs:5, rt:5, i:16 }
encoding J { op:6, a:26 }

instr add  add rd:REG(w), rs:REG(r), rt:REG(r)  { @R op=0, f=0x20; }
instr addu  addu rd:REG(w), rs:REG(r), rt:REG(r)  { @R op=0, f=0x21; }
instr addi  addi rt:REG(w), rs:REG(r), i:IMM  { @I op=8; }
instr addiu  addiu rt:REG(w), rs:REG(r), i:IMM  { @I op=9; }
instr sub  sub rd:REG(w), rs:REG(r), rt:REG(r)  { @R op=0, f=0x22; }
instr subu  subu rd:REG(w), rs:REG(r), rt:REG(r)  { @R op=0, f=0x23; }
instr mult  mult lo:REG(w), hi:REG(w), rs:REG(r), rt:REG(r)  { @R op=0, f=0x18; }
instr multu  multu lo:REG(w), hi:REG(w), rs:REG(r), rt:REG(r)  { @R op=0, f=0x19; }
instr div  div lo:REG(w), hi:REG(w), rs:REG(r), rt:REG(r)  { @R op=0, f=0x1a; }
instr divu  divu lo:REG(w), hi:REG(w), rs:REG(r), rt:REG(r)  { @R op=0, f=0x1b; }
instr(memory) lw  lw rt:REG(w), [rs:REG(r) + i:IMM]  { @I op=0x23; }
instr(memory) lh  lh rt:REG(w), [rs:REG(r) + i:IMM]  { @I op=0x21; }
instr(memory) lhu  lhu rt:REG(w), [rs:REG(r) + i:IMM]  { @I op=0x25; }
instr(memory) lb  lb rt:REG(w), [rs:REG(r) + i:IMM]  { @I op=0x20; }
instr(memory) lbu  lbu rt:REG(w), [rs:REG(r) + i:IMM]  { @I op=0x24; }
instr(memory) sw  sw rt:REG(r), [rs:REG(r) + i:IMM]  { @I op=0x2b; }
instr(memory) sh  sh rt:REG(r), [rs:REG(r) + i:IMM]  { @I op=0x29; }
instr(memory) sb  sb rt:REG(r), [rs:REG(r) + i:IMM]  { @I op=0x28; }
instr lui  lui rt:REG(w), i:IMM  { @I op=0xf; }
instr mfhi  mfhi rd:REG(w), hi:REG(r)  { @R op=0, f=0x10; }
instr mflo  mflo rd:REG(w), lo:REG(r)  { @R op=0, f=0x12; }
instr and  and rd:REG(w), rs:REG(r), rt:REG(r)  { @R op=0, f=0x24; }
instr andi  andi rt:REG(w), rs:REG(r), i:IMM  { @I op=0xc; }
instr or  or rd:REG(w), rs:REG(r), rt:REG(r)  { @R op=0, f=0x25; }
instr ori  ori rt:REG(w), rs:REG(r), i:IMM  { @I op=0xd; }
instr xor  xor rd:REG(w), rs:REG(r), rt:REG(r)  { @R op=0, f=0x26; }
instr nor  nor rd:REG(w), rs:REG(r), rt:REG(r)  { @R op=0, f=0x27; }
instr slt  slt rd:REG(w), rs:REG(r), rt:REG(r)  { @R op=0, f=0x2a; }
instr slti  slti rt:REG(w), rs:REG(r), i:IMM  { @I op=0xa; }
instr sltu  sltu rd:REG(w), rs:REG(r), rt:REG(r)  { @R op=0, f=0x2b; }
instr sltiu  sltiu rt:REG(w), rs:REG(r), i:IMM  { @I op=0xb; }
instr sll  sll rd:REG(w), rt:REG(r), sh:IMM  { @R op=0, f=0; }
instr srl  srl rd:REG(w), rt:REG(r), sh:IMM  { @R op=0, f=2; }
instr sra  sra rd:REG(w), rt:REG(r), sh:IMM  { @R op=0, f=3; }
instr sllv  sllv rd:REG(w), rt:REG(r), rs:REG(r)  { @R op=0, f=4; }
instr srlv  srlv rd:REG(w), rt:REG(r), rs:REG(r)  { @R op=0, f=6; }
instr srav  srav rd:REG(w), rt:REG(r), rs:REG(r)  { @R op=0, f=7; }

instr(copy) move  move rd:REG(w), rs:REG(r)  { @R op=0, f=0x20, rt=0; } update
{
	if (%rd == %rs)
		return true;
	return false;
}

instr addstack  addi rt:REG(w), var:STACKVAR
{
	if ((%var:offset >= -0x8000) && (%var:offset < 0x8000))
		@I op=9, rs=%var:base, i=%var:offset; // addiu
	else
	{
		@I op=0xf, rt=%var:temp, i=%var:offset >> 16; // lui
		@I op=0xd, rt=%var:temp, rs=%var:temp, i=%var:offset & 0xffff; // ori
		@R op=0, f=0x21, rd=%rt, rs=%var:base, rt=%var:temp; // addu
	}
}

instr substack  subi rt:REG(w), var:STACKVAR
{
	if ((%var:offset > -0x8000) && (%var:offset <= 0x8000))
		@I op=9, rs=%var:base, i=-%var:offset; // addiu
	else
	{
		@I op=0xf, rt=%var:temp, i=%var:offset >> 16; // lui
		@I op=0xd, rt=%var:temp, rs=%var:temp, i=%var:offset & 0xffff; // ori
		@R op=0, f=0x23, rd=%rt, rs=%var:base, rt=%var:temp; // subu
	}
}

#define STACK_MEM_OP(cls, name, regaccess, opcode) \
instr(memory) cls  name rt:REG(regaccess), [var:STACKVAR] \
{ \
	if ((%var:offset >= -0x8000) && (%var:offset < 0x8000)) \
		@I op=opcode, rs=%var:base, i=%var:offset; \
	else \
	{ \
		@I op=0xf, rt=%var:temp, i=%var:offset >> 16; \
		@I op=0xd, rt=%var:temp, rs=%var:temp, i=%var:offset & 0xffff; \
		@I op=0, f=0x21, rd=%var:temp, rs=%var:base, rt=%var:temp; \
		@I op=opcode, rs=%var:temp, i=0; \
	} \
}

STACK_MEM_OP(lbstack, lb, w, 0x20)
STACK_MEM_OP(lbustack, lbu, w, 0x24)
STACK_MEM_OP(lhstack, lh, w, 0x21)
STACK_MEM_OP(lhustack, lhu, w, 0x25)
STACK_MEM_OP(lwstack, lw, w, 0x23)
STACK_MEM_OP(sbstack, sb, r, 0x28)
STACK_MEM_OP(shstack, sh, r, 0x29)
STACK_MEM_OP(swstack, sw, r, 0x2b)

#define NOP @R op=0, f=0, rs=0, rd=0, rt=0, sh=0

#define BRANCH_RELOC(bits) \
	Relocation reloc; \
	reloc.type = CODE_RELOC_RELATIVE_32_FIELD; \
	reloc.overflow = NULL; \
	reloc.instruction = out->len - 8; \
	reloc.offset = out->len - 8; \
	reloc.target = %dest:block; \
	reloc.bitOffset = 0; \
	reloc.bitSize = bits; \
	reloc.bitShift = 2; \
	out->relocs.push_back(reloc);

instr(branch) beq  beq rs:REG(r), rt:REG(r), dest:FUNCTION
{
	@I op=4, i=0;
	NOP;
	BRANCH_RELOC(16);
}

instr(branch) bne  bne rs:REG(r), rt:REG(r), dest:FUNCTION
{
	@I op=5, i=0;
	NOP;
	BRANCH_RELOC(16);
}

instr(branch) bgez  bgez rs:REG(r), dest:FUNCTION
{
	@I op=1, rt=1, i=0;
	NOP;
	BRANCH_RELOC(16);
}

instr(branch) bgezal  bgezal rs:REG(r), dest:FUNCTION
{
	@I op=1, rt=0x11, i=0;
	NOP;
	BRANCH_RELOC(16);
}

instr(branch) bgtz  bne rs:REG(r), dest:FUNCTION
{
	@I op=7, rt=0, i=0;
	NOP;
	BRANCH_RELOC(16);
}

instr(branch) blez  bne rs:REG(r), dest:FUNCTION
{
	@I op=6, rt=0, i=0;
	NOP;
	BRANCH_RELOC(16);
}

instr(branch) bltz  bne rs:REG(r), dest:FUNCTION
{
	@I op=1, rt=0, i=0;
	NOP;
	BRANCH_RELOC(16);
}

instr(branch) bltzal  bne rs:REG(r), dest:FUNCTION
{
	@I op=0x10, rt=0, i=0;
	NOP;
	BRANCH_RELOC(16);
}

instr(call) call  call dest:FUNCTION, retval:REG(w), retvalhigh:REG(w), reads:REGLIST(r)
{
	@I op=1, rs=0, rt=0x11, i=0; // bgezal zero
	NOP;
	BRANCH_RELOC(16);
}

instr(call) callr  callr rs:REG(r), retval:REG(w), retvalhigh:REG(w), reads:REGLIST(r)
{
	@R op=0, f=9, rd=31, sh=0; // jalr
	NOP;
}

instr(branch) jr  jr rs:REG(r)  { @R op=0, f=8; NOP; }
instr(call) jalr  jalr rd:REG(w), rs:REG(r)  { @R op=0, f=9, sh=0; NOP; }

instr(branch) syscall  syscall num:REG(r), retval:REG(w), error:REG(w), writes:REGLIST(w), reads:REGLIST(r)
{
	@R op=0, f=0xc; // syscall
	NOP;
	@I op=4, rs=%error, rt=0, i=2; // beq %error, zero
	NOP;
	@R op=0, f=0x23, rd=%retval, rs=0, rt=%retval; // subu %retval, zero, %retval
}

instr break  break  { @R op=0, f=0xd; }

instr ldglobalptr  ldglobalptr ptr:REG(w), dest:GLOBALVAR
{
	@I op=1, rt=0x11, i=1, rs=0; // bgezal $zero, $pc+4
	NOP;
	@I op=8, rt=%ptr, rs=31, i=4;

	Relocation reloc;
	reloc.type = DATA_RELOC_RELATIVE_32_FIELD;
	reloc.overflow = NULL;
	reloc.instruction = out->len - 4;
	reloc.offset = out->len - 4;
	reloc.dataOffset = %dest:offset;
	reloc.bitOffset = 0;
	reloc.bitSize = 16;
	reloc.bitShift = 0;
	out->relocs.push_back(reloc);
}

instr ldblockptr  ldblockptr ptr:REG(w), dest:FUNCTION
{
	@I op=1, rt=0x11, i=1, rs=0; // bgezal $zero, $pc+4
	NOP;
	@I op=8, rt=%ptr, rs=31, i=4;

	Relocation reloc;
	reloc.type = CODE_RELOC_RELATIVE_32_FIELD;
	reloc.overflow = NULL;
	reloc.instruction = out->len - 4;
	reloc.offset = out->len - 4;
	reloc.target = %dest:block;
	reloc.bitOffset = 0;
	reloc.bitSize = 16;
	reloc.bitShift = 0;
	out->relocs.push_back(reloc);
}

instr regparam  regparam regs:REGLIST(w)  {} update { return true; }
instr symreturn  symreturn low:REG(r) high:REG(r)  {} update { return true; }

instr saveregs  saveregs {} update
{
	// TODO: Support non-default stack pointer
	vector<uint32_t> clobbered = func->GetClobberedCalleeSavedRegisters();
	int32_t offset = 0;
	offset += settings.stackGrowsUp ? 4 : -4;
	@sw SYMREG_LR, SYMREG_SP, offset;
	offset += settings.stackGrowsUp ? 4 : -4;
	@sw SYMREG_BP, SYMREG_SP, offset;
	for (vector<uint32_t>::iterator i = clobbered.begin(); i != clobbered.end(); i++)
	{
		offset += settings.stackGrowsUp ? 4 : -4;
		@sw SYMREG_NATIVE_REG(*i), SYMREG_SP, offset;
	}

	@addiu SYMREG_SP, SYMREG_SP, offset;
	return true;
}

instr restoreregs  restoreregs {} update
{
	// TODO: Support non-default stack pointer
	vector<uint32_t> clobbered = func->GetClobberedCalleeSavedRegisters();
	uint32_t stackSize = 8 + (clobbered.size() * 4);
	int32_t offset = 4;
	if (settings.stackGrowsUp)
		@lw SYMREG_LR, SYMREG_SP, offset - stackSize;
	else
		@lw SYMREG_LR, SYMREG_SP, stackSize - offset;
	offset += 4;
	if (settings.stackGrowsUp)
		@lw SYMREG_BP, SYMREG_SP, offset - stackSize;
	else
		@lw SYMREG_BP, SYMREG_SP, stackSize - offset;
	for (vector<uint32_t>::iterator i = clobbered.begin(); i != clobbered.end(); i++)
	{
		offset += 4;
		if (settings.stackGrowsUp)
			@lw SYMREG_NATIVE_REG(*i), SYMREG_SP, offset - stackSize;
		else
			@lw SYMREG_NATIVE_REG(*i), SYMREG_SP, stackSize - offset;
	}
	return true;
}


src:IMM16U => dest:IREG  { @ori %dest, SYMREG_ZERO, %src; }
src:IMM16 => dest:IREG  { @addiu %dest, SYMREG_ZERO, %src; }
src:IMM => dest:IREG  { @lui %dest, %src >> 16; @ori %dest, %dest, %src & 0xffff; }
src:IMM16U => dest:IREG64  { @ori %dest:low, SYMREG_ZERO, %src; @ori %dest:high, SYMREG_ZERO, 0; }
src:IMM16 => dest:IREG64  { @addiu %dest:low, SYMREG_ZERO, %src; @addiu %dest:high, SYMREG_ZERO, %src >> 32; }
src:IMM => dest:IREG64
{
	@lui %dest:low, (%src >> 16) & 0xffff;
	@ori %dest:low, %dest:low, %src & 0xffff;
	@lui %dest:high, (%src >> 48) & 0xffff;
	@ori %dest:high, %dest:high, (%src >> 32) & 0xffff;
}

src:IRESULT => dest:IREG(S8)  { @sll %dest, %src, 24; @sra %dest, %dest, 24; }
src:IRESULT => dest:IREG(U8)  { @andi %dest, %src, 0xff; }
src:IRESULT => dest:IREG(S16)  { @sll %dest, %src, 16; @sra %dest, %dest, 16; }
src:IRESULT => dest:IREG(U16)  { @andi %dest, %src, 0xffff; }
src:IRESULT => dest:IREG(32)  {}

func:FUNCTION => dest:IREG  { @ldblockptr %dest, %func, %func->GetIL()[0]; }
ref src:STACKVAR => dest:IREG  { @addstack %dest, %src; }
ref src:GLOBALVAR => dest:IREG  { @ldglobalptr %dest, %src; }

assign dest:IREG src:IREG  { @move %dest, %src; }
assign dest:IREG64 src:IREG64  { @move %dest:low, %src:low; @move %dest:high, %src:high; }

load(S8) addr:IREG => dest:IREG  { @lb %dest, %addr, 0; }
load(S8) add addr:IREG ofs:IMM16 => dest:IREG  { @lb %dest, %addr, %ofs; }
load(S8) ref src:STACKVAR => dest:IREG  { @lbstack %dest, %src; }
load(U8) addr:IREG => dest:IREG  { @lbu %dest, %addr, 0; }
load(U8) add addr:IREG ofs:IMM16 => dest:IREG  { @lbu %dest, %addr, %ofs; }
load(U8) ref src:STACKVAR => dest:IREG  { @lbustack %dest, %src; }
load(S16) addr:IREG => dest:IREG  { @lh %dest, %addr, 0; }
load(S16) add addr:IREG ofs:IMM16 => dest:IREG  { @lh %dest, %addr, %ofs; }
load(S16) ref src:STACKVAR => dest:IREG  { @lhstack %dest, %src; }
load(U16) addr:IREG => dest:IREG  { @lhu %dest, %addr, 0; }
load(U16) add addr:IREG ofs:IMM16 => dest:IREG  { @lhu %dest, %addr, %ofs; }
load(U16) ref src:STACKVAR => dest:IREG  { @lhustack %dest, %src; }
load(32) addr:IREG => dest:IREG  { @lw %dest, %addr, 0; }
load(32) add addr:IREG ofs:IMM16 => dest:IREG  { @lw %dest, %addr, %ofs; }
load(32) ref src:STACKVAR => dest:IREG  { @lwstack %dest, %src; }

load(64) addr:IREG => dest:IREG64
{
	if (m_settings.bigEndian)
	{
		@lw %dest:high, %addr, 0;
		@lw %dest:low, %addr, 4;
	}
	else
	{
		@lw %dest:low, %addr, 0;
		@lw %dest:high, %addr, 4;
	}
}
load(64) add addr:IREG ofs:IMM16M4 => dest:IREG64
{
	if (m_settings.bigEndian)
	{
		@lw %dest:high, %addr, %ofs;
		@lw %dest:low, %addr, %ofs + 4;
	}
	else
	{
		@lw %dest:low, %addr, %ofs;
		@lw %dest:high, %addr, %ofs + 4;
	}
}
load(64) ref src:STACKVAR => dest:IREG64
{
	if (m_settings.bigEndian)
	{
		@lwstack %dest:high, %src:0;
		@lwstack %dest:low, %src:4;
	}
	else
	{
		@lwstack %dest:low, %src:0;
		@lwstack %dest:high, %src:4;
	}
}

store(8) addr:IREG src:IREG  { @sb %src, %addr, 0; }
store(8) add addr:IREG ofs:IMM16 src:IREG  { @sb %src, %addr, %ofs; }
store(8) ref dest:STACKVAR src:IREG  { @sbstack %src, %dest; }
store(16) addr:IREG src:IREG  { @sh %src, %addr, 0; }
store(16) add addr:IREG ofs:IMM16 src:IREG  { @sh %src, %addr, %ofs; }
store(16) ref dest:STACKVAR src:IREG  { @shstack %src, %dest; }
store(32) addr:IREG src:IREG  { @sw %src, %addr, 0; }
store(32) add addr:IREG ofs:IMM16 src:IREG  { @sw %src, %addr, %ofs; }
store(32) ref dest:STACKVAR src:IREG  { @swstack %src, %dest; }

store(64) addr:IREG src:IREG64
{
	if (m_settings.bigEndian)
	{
		@sw %src:high, %addr, 0;
		@sw %src:low, %addr, 4;
	}
	else
	{
		@sw %src:low, %addr, 0;
		@sw %src:high, %addr, 4;
	}
}
store(64) add addr:IREG ofs:IMM16M4 src:IREG64
{
	if (m_settings.bigEndian)
	{
		@sw %src:high, %addr, %ofs;
		@sw %src:low, %addr, %ofs + 4;
	}
	else
	{
		@sw %src:low, %addr, %ofs;
		@sw %src:high, %addr, %ofs + 4;
	}
}
store(64) ref dest:STACKVAR src:IREG64
{
	if (m_settings.bigEndian)
	{
		@swstack %src:high, %dest:0;
		@swstack %src:low, %dest:4;
	}
	else
	{
		@swstack %src:low, %dest:0;
		@swstack %src:high, %dest:4;
	}
}

add a:IREG b:IREG => dest:IRESULT  { @addu %dest, %a, %b; }
add a:IREG b:IMM16 => dest:IRESULT  { @addiu %dest, %a, %b; }
add a:IREG64 b:IREG64 => dest:IREG64
{
	@addu %dest:low, %a:low, %b:low;
	@sltu %dest:high, %dest:low, %b:low;
	@addu %dest:high, %dest:high, %a:high;
	@addu %dest:high, %dest:high, %b:high;
}

sub a:IREG b:IREG => dest:IRESULT  { @subu %dest, %a, %b; }
sub a:IREG b:IMM16NEG => dest:IRESULT  { @addiu %dest, %a, -%b; }
sub a:IREG64 b:IREG64 => dest:IREG64
{
	@subu %dest:low, %a:low, %b:low;
	@sltu %dest:high, %a:low, %b:low;
	@addu %dest:high, %b:high, %dest:high;
	@subu %dest:high, %a:high, %dest:high;
}

#define MUL_INSTR(op) \
op a:IREG b:IREG => dest:IRESULT  { @multu SYMREG_LO, SYMREG_HI, %a, %b; @mflo %dest, SYMREG_LO; } \
op a:IREG b:IREG => dest:IRESULT  { @multu SYMREG_LO, SYMREG_HI, %a, %b; @mflo %dest, SYMREG_LO; } \
op a:IREG64 b:IREG64 => dest:IREG64, temp:IREG \
{ \
	@multu SYMREG_LO, SYMREG_HI, %a:low, %b:low; \
	@mflo %dest:low, SYMREG_LO; \
	@mfhi %dest:high, SYMREG_HI; \
	@multu SYMREG_LO, SYMREG_HI, %a:low, %b:high; \
	@mflo %temp, SYMREG_LO; \
	@addu %dest:high, %dest:high, %temp; \
	@multu SYMREG_LO, SYMREG_HI, %a:high, %b:low; \
	@mflo %temp, SYMREG_LO; \
	@addu %dest:high, %dest:high, %temp; \
}
MUL_INSTR(smul)
MUL_INSTR(umul)

sdiv a:IREG b:IREG => dest:IRESULT  { @div SYMREG_LO, SYMREG_HI, %a, %b; @mflo %dest, SYMREG_LO; }
udiv a:IREG b:IREG => dest:IRESULT  { @divu SYMREG_LO, SYMREG_HI, %a, %b; @mflo %dest, SYMREG_LO; }
smod a:IREG b:IREG => dest:IRESULT  { @div SYMREG_LO, SYMREG_HI, %a, %b; @mfhi %dest, SYMREG_HI; }
umod a:IREG b:IREG => dest:IRESULT  { @divu SYMREG_LO, SYMREG_HI, %a, %b; @mfhi %dest, SYMREG_HI; }

and a:IREG b:IREG => dest:IREG  { @and %dest, %a, %b; }
and a:IREG b:IMM16U => dest:IREG  { @andi %dest, %a, %b; }
and a:IREG64 b:IREG64 => dest:IREG64  { @and %dest:low, %a:low, %b:low; @and %dest:high, %a:high, %b:high; }
or a:IREG b:IREG => dest:IREG  { @or %dest, %a, %b; }
or a:IREG b:IMM16U => dest:IREG  { @ori %dest, %a, %b; }
or a:IREG64 b:IREG64 => dest:IREG64  { @or %dest:low, %a:low, %b:low; @or %dest:high, %a:high, %b:high; }
xor a:IREG b:IREG => dest:IREG  { @xor %dest, %a, %b; }
xor a:IREG64 b:IREG64 => dest:IREG64  { @xor %dest:low, %a:low, %b:low; @xor %dest:high, %a:high, %b:high; }
not or a:IREG b:IREG => dest:IRESULT  { @nor %dest, %a, %b; }
not or a:IREG64 b:IREG64 => dest:IREG64  { @nor %dest:low, %a:low, %b:low; @nor %dest:high, %a:high, %b:high; }

shl a:IREG b:IREG => dest:IRESULT  { @sllv %dest, %a, %b; }
shl a:IREG b:IMM => dest:IRESULT  { @sll %dest, %a, %b; }
shr a:IREG b:IREG => dest:IRESULT  { @srlv %dest, %a, %b; }
shr a:IREG b:IMM => dest:IRESULT  { @srl %dest, %a, %b; }
sar a:IREG b:IREG => dest:IRESULT  { @srav %dest, %a, %b; }
sar a:IREG b:IMM => dest:IRESULT  { @sra %dest, %a, %b; }

neg a:IREG => dest:IRESULT  { @sub %dest, SYMREG_ZERO, %a; }
neg a:IREG64 => dest:IREG64
{
	@subu %dest:low, SYMREG_ZERO, %a:low;
	@sltu %dest:high, SYMREG_ZERO, %a:low;
	@addu %dest:high, %a:high, %dest:high;
	@subu %dest:high, SYMREG_ZERO, %dest:high;
}

not a:IREG => dest:IRESULT  { @nor %dest, SYMREG_ZERO, %a; }
not a:IREG64 => dest:IREG64  { @nor %dest:low, SYMREG_ZERO, %a:low; @nor %dest:high, SYMREG_ZERO, %a:high; }

sconvert src:IREG(8) => dest:IREG(16, 32)  { @sll %dest, %src, 24; @sra %dest, %dest, 24; }
sconvert src:IREG(8) => dest:IREG64  { @sll %dest:low, %src, 24; @sra %dest:low, %dest:low, 24; @sra %dest:high, %src, 31; }
uconvert src:IREG(8) => dest:IREG(16, 32)  { @andi %dest, %src, 0xff; }
uconvert src:IREG(8) => dest:IREG64  { @andi %dest:low, %src, 0xff; @ori %dest:high, SYMREG_ZERO, 0; }
sconvert src:IREG(16) => dest:IREG(32)  { @sll %dest, %src, 16; @sra %dest, %dest, 16; }
sconvert src:IREG(16) => dest:IREG64  { @sll %dest:low, %src, 16; @sra %dest:low, %dest:low, 16; @sra %dest:high, %src, 31; }
uconvert src:IREG(16) => dest:IREG(32)  { @andi %dest, %src, 0xffff; }
uconvert src:IREG(16) => dest:IREG64  { @andi %dest:low, %src, 0xffff; @ori %dest:high, SYMREG_ZERO, 0; }
sconvert src:IREG(32) => dest:IREG64  { @move %dest:low, %src; @sra %dest:high, %src, 31; }
uconvert src:IREG(32) => dest:IREG64  { @move %dest:low, %src; @ori %dest:high, SYMREG_ZERO, 0; }
sconvert src:IREG(16,32) => dest:IREG(8)  { @sll %dest, %src, 24; @sra %dest, %dest, 24; }
sconvert src:IREG64 => dest:IREG(8)  { @sll %dest, %src:low, 24; @sra %dest, %dest, 24; }
uconvert src:IREG(16,32) => dest:IREG(8)  { @andi %dest, %src, 0xff; }
uconvert src:IREG64 => dest:IREG(8)  { @andi %dest, %src:low, 0xff; }
sconvert src:IREG(32) => dest:IREG(16)  { @sll %dest, %src, 16; @sra %dest, %dest, 16; }
sconvert src:IREG64 => dest:IREG(16)  { @sll %dest, %src:low, 16; @sra %dest, %dest, 16; }
uconvert src:IREG(32) => dest:IREG(16)  { @andi %dest, %src, 0xffff; }
uconvert src:IREG64 => dest:IREG(16)  { @andi %dest, %src:low, 0xffff; }
sconvert src:IREG64 => dest:IREG(32)  { @move %dest, %src:low; }
uconvert src:IREG64 => dest:IREG(32)  { @move %dest, %src:low; }

breakpoint  { @break; }

function void UnconditionalJump(SymInstrBlock* out, TreeBlock* block)
{
	if ((!m_settings.pad) && (block->GetSource()->GetGlobalIndex() == (m_currentBlock->GetSource()->GetGlobalIndex() + 1)))
	{
		// The destination block is the one just after the current one, just fall through
		return;
	}
	@beq SYMREG_ZERO, SYMREG_ZERO, m_func, block->GetSource();
}

iftrue src:IREG t:BLOCK f:BLOCK  { @bne %src, SYMREG_ZERO, m_func, %t->GetSource(); UnconditionalJump(out, %f); }
iftrue src:IREG64 t:BLOCK f:BLOCK
{
	@bne %src:low, SYMREG_ZERO, m_func, %t->GetSource();
	@bne %src:high, SYMREG_ZERO, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}

ife a:IREG b:IREG t:BLOCK f:BLOCK  { @beq %a, %b, m_func, %t->GetSource(); UnconditionalJump(out, %f); }
ife a:IREG b:ZERO t:BLOCK f:BLOCK  { @beq %a, SYMREG_ZERO, m_func, %t->GetSource(); UnconditionalJump(out, %f); }
ife a:IREG64 b:IREG64 t:BLOCK f:BLOCK
{
	@bne %a:low, %b:low, m_func, %f->GetSource();
	@beq %a:high, %b:high, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}
ife a:IREG64 b:ZERO t:BLOCK f:BLOCK
{
	@bne %a:low, SYMREG_ZERO, m_func, %f->GetSource();
	@beq %a:high, SYMREG_ZERO, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}

ifslt a:IREG b:IREG t:BLOCK f:BLOCK, temp:IREG
{
	@slt %temp, %a, %b;
	@bne %temp, SYMREG_ZERO, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}
ifslt a:IREG b:ZERO t:BLOCK f:BLOCK
{
	@bltz %a, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}
ifslt a:IREG64 b:IREG64 t:BLOCK f:BLOCK, temp:IREG
{
	@slt %temp, %a:high, %b:high;
	@bne %temp, SYMREG_ZERO, m_func, %t->GetSource();
	@bne %a:high, %b:high, m_func, %f->GetSource();
	@sltu %temp, %a:low, %b:low;
	@bne %temp, SYMREG_ZERO, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}
ifslt a:IREG64 b:ZERO t:BLOCK f:BLOCK, temp:IREG
{
	@slt %temp, %a:high, SYMREG_ZERO;
	@bne %temp, SYMREG_ZERO, m_func, %t->GetSource();
	@bne %a:high, SYMREG_ZERO, m_func, %f->GetSource();
	@sltu %temp, %a:low, SYMREG_ZERO;
	@bne %temp, SYMREG_ZERO, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}

ifult a:IREG b:IREG t:BLOCK f:BLOCK, temp:IREG
{
	@sltu %temp, %a, %b;
	@bne %temp, SYMREG_ZERO, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}
ifult a:IREG b:ZERO t:BLOCK f:BLOCK, temp:IREG
{
	@sltu %temp, %a, SYMREG_ZERO;
	@bne %temp, SYMREG_ZERO, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}
ifult a:IREG64 b:IREG64 t:BLOCK f:BLOCK, temp:IREG
{
	@sltu %temp, %a:high, %b:high;
	@bne %temp, SYMREG_ZERO, m_func, %t->GetSource();
	@bne %a:high, %b:high, m_func, %f->GetSource();
	@sltu %temp, %a:low, %b:low;
	@bne %temp, SYMREG_ZERO, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}
ifult a:IREG64 b:ZERO t:BLOCK f:BLOCK, temp:IREG
{
	@sltu %temp, %a:high, SYMREG_ZERO;
	@bne %temp, SYMREG_ZERO, m_func, %t->GetSource();
	@bne %a:high, SYMREG_ZERO, m_func, %f->GetSource();
	@sltu %temp, %a:low, SYMREG_ZERO;
	@bne %temp, SYMREG_ZERO, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}

ifsle a:IREG b:IREG t:BLOCK f:BLOCK, temp:IREG
{
	@slt %temp, %b, %a;
	@beq %temp, SYMREG_ZERO, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}
ifsle a:IREG b:ZERO t:BLOCK f:BLOCK, temp:IREG
{
	@blez %a, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}
ifsle a:IREG64 b:IREG64 t:BLOCK f:BLOCK, temp:IREG
{
	@slt %temp, %a:high, %b:high;
	@bne %temp, SYMREG_ZERO, m_func, %t->GetSource();
	@bne %a:high, %b:high, m_func, %f->GetSource();
	@sltu %temp, %b:low, %a:low;
	@beq %temp, SYMREG_ZERO, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}
ifsle a:IREG64 b:ZERO t:BLOCK f:BLOCK, temp:IREG
{
	@slt %temp, %a:high, SYMREG_ZERO;
	@bne %temp, SYMREG_ZERO, m_func, %t->GetSource();
	@bne %a:high, SYMREG_ZERO, m_func, %f->GetSource();
	@sltu %temp, SYMREG_ZERO, %a:low;
	@beq %temp, SYMREG_ZERO, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}

ifule a:IREG b:IREG t:BLOCK f:BLOCK, temp:IREG
{
	@sltu %temp, %b, %a;
	@beq %temp, SYMREG_ZERO, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}
ifule a:IREG b:ZERO t:BLOCK f:BLOCK, temp:IREG
{
	@sltu %temp, SYMREG_ZERO, %a;
	@beq %temp, SYMREG_ZERO, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}
ifule a:IREG64 b:IREG64 t:BLOCK f:BLOCK, temp:IREG
{
	@sltu %temp, %a:high, %b:high;
	@bne %temp, SYMREG_ZERO, m_func, %t->GetSource();
	@bne %a:high, %b:high, m_func, %f->GetSource();
	@sltu %temp, %b:low, %a:low;
	@beq %temp, SYMREG_ZERO, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}
ifule a:IREG64 b:ZERO t:BLOCK f:BLOCK, temp:IREG
{
	@sltu %temp, %a:high, SYMREG_ZERO;
	@bne %temp, SYMREG_ZERO, m_func, %t->GetSource();
	@bne %a:high, SYMREG_ZERO, m_func, %f->GetSource();
	@sltu %temp, SYMREG_ZERO, %a:low;
	@beq %temp, SYMREG_ZERO, m_func, %t->GetSource();
	UnconditionalJump(out, %f);
}

goto dest:BLOCK  { UnconditionalJump(out, %dest); }
goto dest:IREG  { @jr %dest; }

function void AdjustStackAfterCall(SymInstrBlock* out, uint32_t stackAdjust)
{
	if (stackAdjust != 0)
		@addiu SYMREG_SP, SYMREG_SP, m_settings.stackGrowsUp ? -stackAdjust : stackAdjust;
}

call func:FUNCTION reads:INPUT stackAdjust:IMM16 => dest:INTEGER_RETURN_VALUE
{
	@call %func, %func->GetIL()[0], %dest, SYMREG_NONE, %reads;
	AdjustStackAfterCall(out, (uint32_t)%stackAdjust);
}

call func:FUNCTION reads:INPUT stackAdjust:IMM16 => dest:INTEGER_RETURN_VALUE_64
{
	@call %func, %func->GetIL()[0], %dest:low, %dest:high, %reads;
	AdjustStackAfterCall(out, (uint32_t)%stackAdjust);
}

callvoid func:FUNCTION reads:INPUT stackAdjust:IMM16
{
	@call %func, %func->GetIL()[0], SYMREG_NONE, SYMREG_NONE, %reads;
	AdjustStackAfterCall(out, (uint32_t)%stackAdjust);
}

call func:IREG reads:INPUT stackAdjust:IMM16 => dest:INTEGER_RETURN_VALUE
{
	@callr %func, %dest, SYMREG_NONE, %reads;
	AdjustStackAfterCall(out, (uint32_t)%stackAdjust);
}

call func:IREG reads:INPUT stackAdjust:IMM16 => dest:INTEGER_RETURN_VALUE_64
{
	@callr %func, %dest:low, %dest:high, %reads;
	AdjustStackAfterCall(out, (uint32_t)%stackAdjust);
}

callvoid func:IREG reads:INPUT stackAdjust:IMM16
{
	@callr %func, SYMREG_NONE, SYMREG_NONE, %reads;
	AdjustStackAfterCall(out, (uint32_t)%stackAdjust);
}

function bool GenerateReturnVoid(SymInstrBlock* out)
{
	// Restore frame pointer (if present) and adjust stack
	if (m_framePointerEnabled)
	{
		@move SYMREG_SP, SYMREG_BP;
	}
	else
	{
		// TODO: Support frames without a frame pointer
		return false;
	}

	@restoreregs;

	// Return to caller
	@jr SYMREG_LR;
	return true;
}

return src:IREG, retval:INTEGER_RETURN_VALUE  { @move %retval, %src; GenerateReturnVoid(out); @symreturn %retval, SYMREG_NONE; }
return src:IREG64, retval:INTEGER_RETURN_VALUE_64
{
	@move %retval:low, %src:low;
	@move %retval:high, %src:high;
	GenerateReturnVoid(out);
	@symreturn %retval:low, %retval:high;
}
returnvoid  { GenerateReturnVoid(out); }

alloca size:IREG => result:IREG, temp:IREG
{
	if (m_settings.stackGrowsUp)
	{
		@addiu SYMREG_SP, SYMREG_SP, 4;
		@move %result, SYMREG_SP;
		@addu SYMREG_SP, SYMREG_SP, %size;
		@addiu %temp, SYMREG_ZERO, ~3;
		@and SYMREG_SP, SYMREG_SP, %temp;
	}
	else
	{
		@subu SYMREG_SP, SYMREG_SP, %size;
		@addiu %temp, SYMREG_ZERO, ~3;
		@and SYMREG_SP, SYMREG_SP, %temp;
		@move %result, SYMREG_SP;
	}
}

alloca size:IMM16M1 => result:IREG, temp:IREG
{
	if (m_settings.stackGrowsUp)
	{
		@addiu SYMREG_SP, SYMREG_SP, 4;
		@move %result, SYMREG_SP;
		@addiu SYMREG_SP, SYMREG_SP, %size;
		@addiu %temp, SYMREG_ZERO, ~3;
		@and SYMREG_SP, SYMREG_SP, %temp;
	}
	else
	{
		@addiu SYMREG_SP, SYMREG_SP, -%size;
		@addiu %temp, SYMREG_ZERO, ~3;
		@and SYMREG_SP, SYMREG_SP, %temp;
		@move %result, SYMREG_SP;
	}
}

vararg => result:IREG, temp:IREG  { @addstack %result, SYMREG_BP, m_varargStart, 0, %temp; }

syscall num:IMM16U reads:INPUT stackAdjust:IMM16 => dest:SYSCALL_RETURN, numreg:SYSCALL_NUM, error:SYSCALL_ERROR_FLAG
{
	vector<uint32_t> writes;
	if (%stackAdjust != 0)
		@addiu SYMREG_SP, SYMREG_SP, -16; // ABI assumes there is space for the first four params
	@ori %numreg, SYMREG_ZERO, %num;
	@syscall %numreg, %dest, %error, writes, %reads;
	if (%stackAdjust != 0)
		AdjustStackAfterCall(out, (uint32_t)%stackAdjust + 16);
}

syscall num:IREG reads:INPUT stackAdjust:IMM16 => dest:SYSCALL_RETURN, numreg:SYSCALL_NUM, error:SYSCALL_ERROR_FLAG
{
	vector<uint32_t> writes;
	if (%stackAdjust != 0)
		@addiu SYMREG_SP, SYMREG_SP, -16; // ABI assumes there is space for the first four params
	@move %numreg, %num;
	@syscall %numreg, %dest, %error, writes, %reads;
	if (%stackAdjust != 0)
		AdjustStackAfterCall(out, (uint32_t)%stackAdjust + 16);
}

syscall num:IMM16U reads:INPUT stackAdjust:IMM16 => dest:SYSCALL_RETURN_64, numreg:SYSCALL_NUM, error:SYSCALL_ERROR_FLAG
{
	vector<uint32_t> writes;
	writes.push_back(%dest:high);
	if (%stackAdjust != 0)
		@addiu SYMREG_SP, SYMREG_SP, -16; // ABI assumes there is space for the first four params
	@ori %numreg, SYMREG_ZERO, %num;
	@syscall %numreg, %dest:low, %error, writes, %reads;
	if (%stackAdjust != 0)
		AdjustStackAfterCall(out, (uint32_t)%stackAdjust + 16);
}

syscall num:IREG reads:INPUT stackAdjust:IMM16 => dest:SYSCALL_RETURN_64, numreg:SYSCALL_NUM, error:SYSCALL_ERROR_FLAG
{
	vector<uint32_t> writes;
	writes.push_back(%dest:high);
	if (%stackAdjust != 0)
		@addiu SYMREG_SP, SYMREG_SP, -16; // ABI assumes there is space for the first four params
	@move %numreg, %num;
	@syscall %numreg, %dest:low, %error, writes, %reads;
	if (%stackAdjust != 0)
		AdjustStackAfterCall(out, (uint32_t)%stackAdjust + 16);
}

push src:IREG
{
	@sw %src, SYMREG_SP, m_settings.stackGrowsUp ? 4 : -4;
	@addiu SYMREG_SP, SYMREG_SP, m_settings.stackGrowsUp ? 4 : -4;
}

push src:IREG64
{
	if (m_settings.bigEndian)
	{
		@sw %src:high, SYMREG_SP, m_settings.stackGrowsUp ? 4 : -8;
		@sw %src:low, SYMREG_SP, m_settings.stackGrowsUp ? 8 : -4;
		@addiu SYMREG_SP, SYMREG_SP, m_settings.stackGrowsUp ? 8 : -8;
	}
	else
	{
		@sw %src:low, SYMREG_SP, m_settings.stackGrowsUp ? 4 : -8;
		@sw %src:high, SYMREG_SP, m_settings.stackGrowsUp ? 8 : -4;
		@addiu SYMREG_SP, SYMREG_SP, m_settings.stackGrowsUp ? 8 : -8;
	}
}

function void GenerateAntiDisassembly(SymInstrBlock* out)
{
}

function bool GenerateFunctionStart(SymInstrBlock* out)
{
	if ((m_func->GetName() == "_start") && m_settings.unsafeStack)
	{
		// This is the start function, and we can't assume we have a safe stack (the code may be
		// at or near the stack pointer), pivot the stack to make it safe
		@addiu SYMREG_SP, SYMREG_SP, -UNSAFE_STACK_PIVOT;
	}

	// Generate function prologue
	if (m_framePointerEnabled)
	{
		@saveregs;
		@move SYMREG_BP, SYMREG_SP;
	}
	else
	{
		@saveregs;
	}

	// Generate a pseudo instruction to ensure the incoming parameters are defined
	vector<uint32_t> incomingRegs;
	for (vector<IncomingParameterCopy>::iterator j = m_paramCopy.begin(); j != m_paramCopy.end(); j++)
	{
		if (j->stackVar != SYMREG_NONE)
			continue;

		incomingRegs.push_back(j->incomingReg);
		if (j->var->GetType()->GetWidth() == 8)
			incomingRegs.push_back(j->incomingReg + 1);
	}

	if (incomingRegs.size() != 0)
		@regparam incomingRegs;

	// Copy parameters into variables so that they can be spilled if needed
	for (vector<IncomingParameterCopy>::iterator j = m_paramCopy.begin(); j != m_paramCopy.end(); j++)
	{
		if (j->stackVar != SYMREG_NONE)
		{
			// Parameter was spilled onto stack
			switch (j->var->GetType()->GetWidth())
			{
			case 1:
				@sbstack j->incomingReg, SYMREG_BP, j->stackVar, 0, TEMP_REGISTER(IREG);
				break;
			case 2:
				@shstack j->incomingReg, SYMREG_BP, j->stackVar, 0, TEMP_REGISTER(IREG);
				break;
			case 4:
				@swstack j->incomingReg, SYMREG_BP, j->stackVar, 0, TEMP_REGISTER(IREG);
				break;
			case 8:
				if (m_settings.bigEndian)
				{
					@swstack j->incomingHighReg, SYMREG_BP, j->stackVar, 0, TEMP_REGISTER(IREG);
					@swstack j->incomingReg, SYMREG_BP, j->stackVar, 4, TEMP_REGISTER(IREG);
				}
				else
				{
					@swstack j->incomingReg, SYMREG_BP, j->stackVar, 0, TEMP_REGISTER(IREG);
					@swstack j->incomingHighReg, SYMREG_BP, j->stackVar, 4, TEMP_REGISTER(IREG);
				}
				break;
			default:
				fprintf(stderr, "error: spilling invalid parameter\n");
				return false;
			}
		}
		else
		{
			// Parameter is in an integer register
			uint32_t newReg = TEMP_REGISTER(IREG);
			uint32_t newHighReg = SYMREG_NONE;
			if (j->var->GetType()->GetWidth() == 8)
				newHighReg = TEMP_REGISTER(IREG);

			@move newReg, j->incomingReg;
			if (newHighReg != SYMREG_NONE)
				@move newHighReg, j->incomingHighReg;
			m_vars.registerVariables[j->var] = newReg;
			if (newHighReg != SYMREG_NONE)
				m_vars.highRegisterVariables[j->var] = newHighReg;
		}
	}

	if (m_framePointerEnabled)
	{
		uint32_t temp = TEMP_REGISTER(IREG);
		if (m_settings.stackGrowsUp)
			@addstack SYMREG_SP, SYMREG_SP, SYMVAR_FRAME_SIZE, 0, temp;
		else
			@substack SYMREG_SP, SYMREG_SP, SYMVAR_FRAME_SIZE, 0, temp;
	}

	return true;
}

arch function set<uint32_t> GetRegisterClassInterferences(uint32_t cls)
{
	set<uint32_t> result;
	return result;
}

arch function bool DoesRegisterClassConflictWithSpecialRegisters(uint32_t cls)
{
	return false;
}

arch function void LayoutStackFrame()
{
	// Lay out stack variables
	int64_t offset = 0;
	for (size_t i = 0; i < m_stackVarOffsets.size(); i++)
	{
		if (m_stackVarIsParam[i])
			continue;

		int64_t align = 1;
		if (m_stackVarWidths[i] >= 4)
			align = 4;
		else if (m_stackVarWidths[i] >= 2)
			align = 2;

		if ((offset & (align - 1)) != 0)
			offset += align - (offset & (align - 1));

		m_stackVarOffsets[i] = offset;
		offset += m_stackVarWidths[i];
	}

	// Ensure stack stays aligned on native boundary
	if (offset & 3)
		offset += 4 - (offset & 3);

	m_stackFrameSize = offset;

	// Adjust variable offsets to be relative to the frame pointer (negative offsets)
	if (m_settings.stackGrowsUp)
	{
		for (size_t i = 0; i < m_stackVarOffsets.size(); i++)
		{
			if (!m_stackVarIsParam[i])
				m_stackVarOffsets[i] -= offset;
		}
	}

	for (size_t i = 0; i < m_stackVarOffsets.size(); i++)
	{
		if (m_stackVarIsParam[i])
			continue;
		if (m_settings.stackGrowsUp)
			m_stackVarOffsets[i] += m_stackFrameSize;
		else
			m_stackVarOffsets[i] -= m_stackFrameSize;
	}

	// Account for callee saved registers
	int32_t adjust = 8 + (m_clobberedCalleeSavedRegs.size() * 4);
	for (size_t i = 0; i < m_stackVarOffsets.size(); i++)
	{
		if (!m_stackVarIsParam[i])
			continue;

		if (m_settings.stackGrowsUp)
			m_stackVarOffsets[i] -= adjust;
		else
			m_stackVarOffsets[i] += adjust;
	}
}

arch function bool GenerateSpillLoad(uint32_t reg, uint32_t var, int64_t offset,
	ILParameterType type, vector<SymInstr*>& code)
{
	uint32_t temp = AddRegister(IREG);
	switch (type)
	{
	case ILTYPE_INT8:
		@lbstack reg, SYMREG_BP, var, offset, temp;
		break;
	case ILTYPE_INT16:
		@lhstack reg, SYMREG_BP, var, offset, temp;
		break;
	case ILTYPE_INT32:
	case ILTYPE_INT64: // Uses two 32-bit regs
		@lwstack reg, SYMREG_BP, var, offset, temp;
		break;
	default:
		return false;
	}

	return true;
}

arch function bool GenerateSpillStore(uint32_t reg, uint32_t var, int64_t offset,
	ILParameterType type, vector<SymInstr*>& code)
{
	uint32_t temp = AddRegister(IREG);
	switch (type)
	{
	case ILTYPE_INT8:
		@sbstack reg, SYMREG_BP, var, offset, temp;
		break;
	case ILTYPE_INT16:
		@shstack reg, SYMREG_BP, var, offset, temp;
		break;
	case ILTYPE_INT32:
	case ILTYPE_INT64: // Uses two 32-bit regs
		@swstack reg, SYMREG_BP, var, offset, temp;
		break;
	default:
		return false;
	}

	return true;
}

arch function void PrintRegister(uint32_t reg)
{
	if (reg == SYMREG_ZERO)
		fprintf(stderr, "zero");
	else if (reg == SYMREG_NATIVE_REG(REG_AT))
		fprintf(stderr, "at");
	else if ((reg >= SYMREG_NATIVE_REG(REG_V(0))) && (reg < SYMREG_NATIVE_REG(REG_V(2))))
		fprintf(stderr, "v%d", reg - SYMREG_NATIVE_REG(REG_V(0)));
	else if ((reg >= SYMREG_NATIVE_REG(REG_A(0))) && (reg < SYMREG_NATIVE_REG(REG_A(8))))
		fprintf(stderr, "a%d", reg - SYMREG_NATIVE_REG(REG_A(0)));
	else if ((reg >= SYMREG_NATIVE_REG(REG_T(0))) && (reg < SYMREG_NATIVE_REG(REG_T(0) + 8)))
		fprintf(stderr, "t%d", reg - SYMREG_NATIVE_REG(REG_T(0)));
	else if ((reg >= SYMREG_NATIVE_REG(REG_T(8))) && (reg < SYMREG_NATIVE_REG(REG_T(10))))
		fprintf(stderr, "t%d", (reg - SYMREG_NATIVE_REG(REG_T(8))) + 8);
	else if ((reg >= SYMREG_NATIVE_REG(REG_S(0))) && (reg < SYMREG_NATIVE_REG(REG_S(10))))
		fprintf(stderr, "s%d", reg - SYMREG_NATIVE_REG(REG_S(0)));
	else if ((reg >= SYMREG_NATIVE_REG(REG_K(0))) && (reg < SYMREG_NATIVE_REG(REG_K(2))))
		fprintf(stderr, "k%d", reg - SYMREG_NATIVE_REG(REG_K(0)));
	else if (reg == SYMREG_NATIVE_REG(REG_GP))
		fprintf(stderr, "gp");
	else if (reg == SYMREG_NATIVE_REG(REG_SP))
		fprintf(stderr, "sp");
	else if (reg == SYMREG_NATIVE_REG(REG_FP))
		fprintf(stderr, "fp");
	else if (reg == SYMREG_NATIVE_REG(REG_RA))
		fprintf(stderr, "ra");
	else if (reg == SYMREG_NATIVE_REG(REG_LO))
		fprintf(stderr, "lo");
	else if (reg == SYMREG_NATIVE_REG(REG_HI))
		fprintf(stderr, "hi");
	else
		SymInstrFunction::PrintRegister(reg);
}

