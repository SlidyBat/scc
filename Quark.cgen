arch Quark 32

#define FPU_REG(n) ((n) + 32)
#define SYMREG_FPU_REG(n) SYMREG_NATIVE_REG((n) + 32)

registerclass default IREG(8,16,32)
registerclass INTEGER_RETURN_VALUE(8,16,32) fixed { 1 } : IREG
registerclass INTEGER_RETURN_VALUE_HIGH(32) fixed { 2 } : IREG
registerclass SYSCALL_RETURN(8,16,32) fixed { 1 } : IREG
registerclass SYSCALL_RETURN_HIGH(32) fixed { 2 } : IREG
registerclass FREG(F32,F64)
registerclass FLOAT_RETURN_VALUE(F32,F64) fixed { FPU_REG(0) } : FREG
largeregisterclass IREG64(64) IREG IREG
largeregisterclass INTEGER_RETURN_VALUE_64(64) INTEGER_RETURN_VALUE INTEGER_RETURN_VALUE_HIGH
largeregisterclass SYSCALL_RETURN_64(64) SYSCALL_RETURN SYSCALL_RETURN_HIGH
tempregisterclass IRESULT(8,16,32) IREG

registerclass INTEGER_PARAM_0(8,16,32) fixed { 1 } : IREG
registerclass INTEGER_PARAM_1(8,16,32) fixed { 2 } : IREG
registerclass INTEGER_PARAM_2(8,16,32) fixed { 3 } : IREG
registerclass INTEGER_PARAM_3(8,16,32) fixed { 4 } : IREG
registerclass INTEGER_PARAM_4(8,16,32) fixed { 5 } : IREG
registerclass INTEGER_PARAM_5(8,16,32) fixed { 6 } : IREG
registerclass INTEGER_PARAM_6(8,16,32) fixed { 7 } : IREG
registerclass INTEGER_PARAM_7(8,16,32) fixed { 8 } : IREG

registerclass SYSCALL_PARAM_0(8,16,32) fixed { 1 } : IREG
registerclass SYSCALL_PARAM_1(8,16,32) fixed { 2 } : IREG
registerclass SYSCALL_PARAM_2(8,16,32) fixed { 3 } : IREG
registerclass SYSCALL_PARAM_3(8,16,32) fixed { 4 } : IREG
registerclass SYSCALL_PARAM_4(8,16,32) fixed { 5 } : IREG
registerclass SYSCALL_PARAM_5(8,16,32) fixed { 6 } : IREG
registerclass SYSCALL_PARAM_6(8,16,32) fixed { 7 } : IREG
registerclass SYSCALL_PARAM_7(8,16,32) fixed { 8 } : IREG

registerclass FLOAT_PARAM_0(F32,F64) fixed { FPU_REG(0) } : FREG
registerclass FLOAT_PARAM_1(F32,F64) fixed { FPU_REG(1) } : FREG
registerclass FLOAT_PARAM_2(F32,F64) fixed { FPU_REG(2) } : FREG
registerclass FLOAT_PARAM_3(F32,F64) fixed { FPU_REG(3) } : FREG
registerclass FLOAT_PARAM_4(F32,F64) fixed { FPU_REG(4) } : FREG
registerclass FLOAT_PARAM_5(F32,F64) fixed { FPU_REG(5) } : FREG
registerclass FLOAT_PARAM_6(F32,F64) fixed { FPU_REG(6) } : FREG
registerclass FLOAT_PARAM_7(F32,F64) fixed { FPU_REG(7) } : FREG

callersaved { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, FPU_REG(0), FPU_REG(1), FPU_REG(2), FPU_REG(3), FPU_REG(4),
	FPU_REG(5), FPU_REG(6), FPU_REG(7), FPU_REG(8), FPU_REG(9), FPU_REG(10), FPU_REG(11), FPU_REG(12), FPU_REG(13),
	FPU_REG(14), FPU_REG(15) }
calleesaved { 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, FPU_REG(31), FPU_REG(30), FPU_REG(29), FPU_REG(28),
	FPU_REG(27), FPU_REG(26), FPU_REG(25), FPU_REG(24), FPU_REG(23), FPU_REG(22), FPU_REG(21), FPU_REG(20), FPU_REG(19),
	FPU_REG(18), FPU_REG(17), FPU_REG(16) }

special SYMREG_SP { 0 }
special SYMREG_BP { 29 }
special SYMREG_LR { 30 }
special SYMREG_IP { 31 }

immediateclass IMM11
{
	if (value < -1024)
		return false;
	if (value > 1023)
		return false;
	return true;
}

immediateclass IMM11M4
{
	if (value < -1024)
		return false;
	if (value > (1023 - 4))
		return false;
	return true;
}

immediateclass IMM17
{
	if (value < -65536)
		return false;
	if (value > 65535)
		return false;
	return true;
}

#define QUARK_COND_LT   0
#define QUARK_COND_LE   1
#define QUARK_COND_GE   2
#define QUARK_COND_GT   3
#define QUARK_COND_EQ   4
#define QUARK_COND_NE   5
#define QUARK_COND_BTNZ 6
#define QUARK_COND_BTZ  7
#define QUARK_COND_NAN  6
#define QUARK_COND_INF  7
#define QUARK_COND(c, i) (((c) & 7) | (((i) & 3) << 3))
#define QUARK_ALWAYS      0
#define QUARK_NEVER       1
#define QUARK_IF_FALSE(n) ((((n) & 3) << 1) | 8)
#define QUARK_IF_TRUE(n)  ((((n) & 3) << 1) | 9)

encoding DEFAULT { cond=0: 4, op: 6, a: 5, b: 5, 0: 2, c: 5, d: 5 }
encoding IMM11 { cond=0: 4, op: 6, a: 5, b: 5, 1: 1, i: 11 }
encoding IMM17 { cond=0: 4, op: 6, a: 5, i: 17 }
encoding IMM22 { cond=0: 4, op: 6, i: 22 }

instr function void RelativeLoadOverflowHandler(OutputBlock* out, Relocation& reloc)
{
	size_t start = reloc.instruction;
	uint32_t* oldInstr = (uint32_t*)((size_t)out->code + start);

	if (reloc.bitSize == 17)
	{
		// Was a 17-bit immediate, use a full 32-bit immediate
		uint32_t instrs[3];
		uint32_t oldOpcode = (oldInstr[0] >> 22) & 0x3f;
		int32_t oldOffset = oldInstr[0] & 0x1ffff;
		int oldRegA = (oldInstr[1] >> 17) & 31;
		int oldRegB = (oldInstr[1] >> 12) & 31;
		if (oldOffset & 0x10000)
			oldOffset |= 0xfffe0000;

		oldOffset -= 4;

		instrs[0] = @@IMM17 op=20, a=reloc.extra, i=oldOffset; // ldi
		instrs[1] = @@IMM17 op=21, a=reloc.extra, i=(oldOffset < 0) ? -1 : 0; // ldih
		instrs[2] = @@DEFAULT op=oldOpcode, a=oldRegA, b=oldRegB, c=reloc.extra, d=0;

		out->ReplaceInstruction(start, 8, instrs, 12, 0);

		reloc.type = DATA_RELOC_RELATIVE_64_SPLIT_FIELD;
		reloc.bitSize = 16;
		reloc.secondBitOffset = 0;
		reloc.secondBitSize = 16;
		reloc.secondBitShift = 16;
	}
	else
	{
		// Was an 11-bit immediate, extend to a 17-bit immediate
		uint32_t instrs[2];
		uint32_t oldOpcode = (oldInstr[0] >> 22) & 0x3f;
		int32_t oldOffset = oldInstr[0] & 0x7ff;
		int oldRegA = (oldInstr[0] >> 17) & 31;
		int oldRegB = (oldInstr[0] >> 12) & 31;
		if (oldOffset & 0x400)
			oldOffset |= 0xfffff800;

		oldOffset -= 4;

		instrs[0] = @@IMM17 op=20, a=reloc.extra, i=oldOffset; // ldi
		instrs[1] = @@DEFAULT op=oldOpcode, a=oldRegA, b=oldRegB, c=reloc.extra, d=0;

		out->ReplaceInstruction(start, 4, instrs, 8, 0);

		reloc.bitSize = 17;
	}
}

instr function void EmitStack(SymInstrFunction* func, OutputBlock* out, uint32_t opcode, uint32_t a,
	uint32_t base, int32_t offset, uint32_t temp)
{
	if ((offset >= -0x400) && (offset <= 0x3ff))
		@IMM11 op=opcode, a=a, b=base, i=offset;
	else if ((offset >= -0x10000) && (offset <= 0xffff))
	{
		@IMM17 op=20, a=temp, i=offset;
		@DEFAULT op=opcode, a=a, b=base, c=temp, d=0;
	}
	else
	{
		@IMM17 op=20, a=temp, i=offset;
		@IMM17 op=21, a=temp, i=(offset) >> 16;
		@DEFAULT op=opcode, a=a, b=base, c=temp, d=0;
	}
}

instr function void EmitGlobal(SymInstrFunction* func, OutputBlock* out, uint32_t opcode, uint32_t a,
	uint32_t base, int32_t offset, uint32_t temp)
{
	@IMM11 op=opcode, a=a, b=base, i=0;

	Relocation reloc;
	reloc.type = DATA_RELOC_RELATIVE_32_FIELD;
	reloc.bitOffset = 0;
	reloc.bitSize = 11;
	reloc.bitShift = 0;
	reloc.offset = out->len - 4;
	reloc.extra = temp;
	reloc.instruction = reloc.offset;
	reloc.dataOffset = offset;
	reloc.overflow = RelativeLoadOverflowHandler;
	out->relocs.push_back(reloc);
}

instr function void EmitBlock(SymInstrFunction* func, OutputBlock* out, uint32_t opcode, uint32_t a,
	uint32_t base, ILBlock* block, uint32_t temp)
{
	@IMM11 op=opcode, a=a, b=base, i=0;

	Relocation reloc;
	reloc.type = CODE_RELOC_RELATIVE_32_FIELD;
	reloc.bitOffset = 0;
	reloc.bitSize = 11;
	reloc.bitShift = 0;
	reloc.offset = out->len - 4;
	reloc.extra = temp;
	reloc.instruction = reloc.offset;
	reloc.target = block;
	reloc.overflow = RelativeLoadOverflowHandler;
	out->relocs.push_back(reloc);
}

#define LOAD_STORE_INSTR(cls, updatecls, stackcls, globalcls, access, name, updatename, opcode, updateopcode) \
instr(memory) cls name a:REG(access), b:REG(r), c:REG(r) << d:IMM { @DEFAULT op=opcode; } \
instr(memory) cls name a:REG(access), b:REG(r), i:IMM { @IMM11 op=opcode; } \
instr(memory) updatecls updatename a:REG(access), b:REG(rw), c:REG(r) << d:IMM { @DEFAULT op=updateopcode; } \
instr(memory) updatecls updatename a:REG(access), b:REG(rw), i:IMM { @IMM11 op=updateopcode; } \
instr(memory) stackcls name a:REG(access), var:STACKVAR { EmitStack(func, out, opcode, %a, %var:base, %var:offset, %var:temp); } \
instr(memory) globalcls name a:REG(access), var:GLOBALVAR { EmitGlobal(func, out, opcode, %a, %var:base, %var:offset, %var:temp); } \

LOAD_STORE_INSTR(Load8, LoadUpdate8, LoadStack8, LoadGlobal8, w, ldb, ldbu, 0, 8)
LOAD_STORE_INSTR(Load16, LoadUpdate16, LoadStack16, LoadGlobal16, w, ldh, ldhu, 1, 9)
LOAD_STORE_INSTR(Load32, LoadUpdate32, LoadStack32, LoadGlobal32, w, ldw, ldwu, 2, 10)
LOAD_STORE_INSTR(LoadFS, LoadUpdateFS, LoadStackFS, LoadGlobalFS, w, ldfs, ldfsu, 48, 52)
LOAD_STORE_INSTR(LoadFD, LoadUpdateFD, LoadStackFD, LoadGlobalFD, w, ldfd, ldfdu, 49, 53)
LOAD_STORE_INSTR(LoadSX8, LoadUpdateSX8, LoadStackSX8, LoadGlobalSX8, w, ldsxb, ldsbxu, 16, 18)
LOAD_STORE_INSTR(LoadSX16, LoadUpdateSX16, LoadStackSX16, LoadGlobalSX16, w, ldsxh, ldsxhu, 17, 19)
LOAD_STORE_INSTR(Store8, StoreUpdate8, StoreStack8, StoreGlobal8, r, stb, stbu, 4, 12)
LOAD_STORE_INSTR(Store16, StoreUpdate16, StoreStack16, StoreGlobal16, r, sth, sthu, 5, 13)
LOAD_STORE_INSTR(Store32, StoreUpdate32, StoreStack32, StoreGlobal32, r, stw, stwu, 6, 14)
LOAD_STORE_INSTR(StoreFS, StoreUpdateFS, StoreStackFS, StoreGlobalFS, r, stfs, stfsu, 50, 54)
LOAD_STORE_INSTR(StoreFD, StoreUpdateFD, StoreStackFD, StoreGlobalFD, r, stfd, stfdu, 51, 55)

instr(memory) LoadMultipleUpdate ldmwu a:REG(w), b:REG(rw), c:REG(r) << d:IMM { @DEFAULT op=11; }
instr(memory) LoadMultipleUpdate ldmwu a:REG(w), b:REG(rw), i:IMM { @IMM11 op=11; }
instr(memory) StoreMultipleUpdate stmwu a:REG(r), b:REG(rw), c:REG(r) << d:IMM { @DEFAULT op=15; }
instr(memory) StoreMultipleUpdate stmwu a:REG(r), b:REG(rw), i:IMM { @IMM11 op=15; }

instr LoadImm ldi a:REG(w), i:IMM { @IMM17 op=20; }
instr LoadImmHigh ldih a:REG(rw), i:IMM { @IMM17 op=21; }

#define BRANCH_RELOC(dest, ofs, size, shift) \
	Relocation reloc; \
	reloc.type = CODE_RELOC_RELATIVE_32_FIELD; \
	reloc.overflow = NULL; \
	reloc.instruction = out->len - 4; \
	reloc.offset = out->len - 4; \
	reloc.target = dest; \
	reloc.bitOffset = ofs; \
	reloc.bitSize = size; \
	reloc.bitShift = shift; \
	out->relocs.push_back(reloc);

instr(branch) Jump jmp dest:FUNCTION
{
	@IMM22 op=22, i=0;
	BRANCH_RELOC(%dest:block, 0, 22, 2);
}

instr(branch, readflags) CondJump jmp cc:IMM = val:IMM, dest:FUNCTION
{
	if (%val)
		@IMM22 cond=QUARK_IF_TRUE(cc), op=22, i=0;
	else
		@IMM22 cond=QUARK_IF_FALSE(cc), op=22, i=0;
	BRANCH_RELOC(%dest:block, 0, 22, 2);
}

instr(call) Call call a:REG(r), retVal:REG(w), retValHigh:REG(w), reads:REGLIST(r) { @DEFAULT op=31, b=6; }
instr(call) Call call dest:FUNCTION, retVal:REG(w), retValHigh:REG(w), reads:REGLIST(r)
{
	@IMM22 op=23, i=0;
	BRANCH_RELOC(%dest:block, 0, 22, 2);
}

instr(branch) SyscallReg syscall a:REG(r), writes:REGLIST(w), reads:REGLIST(r) { @DEFAULT op=31, b=16; }
instr(branch) SyscallImmed syscall i:IMM, writes:REGLIST(w), reads:REGLIST(r) { @IMM22 op=44; }

instr AddStack add a:REG(w), var:STACKVAR { EmitStack(func, out, 24, %a, %var:base, %var:offset, %var:temp); } update
{
	// Delete the instruction if it has no effect
	if ((%a == %var:base) && (%var:offset == 0))
		return true;
	return false;
}

instr SubStack add a:REG(w), var:STACKVAR { EmitStack(func, out, 25, %a, %var:base, %var:offset, %var:temp); } update
{
	// Delete the instruction if it has no effect
	if ((%a == %var:base) && (%var:offset == 0))
		return true;
	return false;
}

instr AddGlobal add a:REG(w), var:GLOBALVAR { EmitGlobal(func, out, 24, %a, %var:base, %var:offset, %var:temp); }
instr AddBlock add a:REG(w), base:REG(r), dest:FUNCTION, temp:TEMP { EmitBlock(func, out, 24, %a, %base, %dest:block, %temp); }

#define ARITH_INSTR(cls, name, opcode) \
instr cls name a:REG(w), b:REG(r), c:REG(r) << d:IMM { @DEFAULT op=opcode; } \
instr cls name a:REG(w), b:REG(r), i:IMM { @IMM11 op=opcode; }
ARITH_INSTR(Add, add, 24)
ARITH_INSTR(Sub, sub, 25)
ARITH_INSTR(Mul, mul, 30)
ARITH_INSTR(Div, div, 32)
ARITH_INSTR(Idiv, idiv, 33)
ARITH_INSTR(Mod, mod, 34)
ARITH_INSTR(Imod, imod, 35)
ARITH_INSTR(And, and, 36)
ARITH_INSTR(Or, or, 37)
ARITH_INSTR(Xor, xor, 38)
ARITH_INSTR(Sar, sar, 39)
ARITH_INSTR(Shl, shl, 40)
ARITH_INSTR(Shr, shr, 41)
ARITH_INSTR(Rol, rol, 42)
ARITH_INSTR(Ror, ror, 43)
instr(readflags, writeflags) Addx addx a:REG(w), b:REG(r), c:REG(r) << d:IMM { @DEFAULT op=26; } \
instr(readflags, writeflags) Addx addx a:REG(w), b:REG(r), i:IMM { @IMM11 op=26; }
instr(readflags, writeflags) Subx subx a:REG(w), b:REG(r), c:REG(r) << d:IMM { @DEFAULT op=27; } \
instr(readflags, writeflags) Subx subx a:REG(w), b:REG(r), i:IMM { @IMM11 op=27; }
instr Mulx mulx d:REG(w), a:REG(w), b:REG(r), c:REG(r) { @DEFAULT op=28; }
instr Imulx imulx d:REG(w), a:REG(w), b:REG(r), c:REG(r) { @DEFAULT op=29; }

#define FLOAT_ARITH_INSTR(cls, immcls, name, opcode) \
instr cls name a:REG(w), b:REG(r), c:REG(r) { @DEFAULT op=opcode; } \
instr immcls name a:REG(w), b:REG(r), c:REG(r) { @IMM11 op=opcode; }
FLOAT_ARITH_INSTR(Fadd, FaddImmed, fadd, 56)
FLOAT_ARITH_INSTR(Fsub, FsubImmed, fsub, 57)
FLOAT_ARITH_INSTR(Fmul, FmulImmed, fmul, 58)
FLOAT_ARITH_INSTR(Fdiv, FdivImmed, fdiv, 59)
FLOAT_ARITH_INSTR(Fmod, FmodImmed, fmod, 60)
FLOAT_ARITH_INSTR(Fpow, FpowImmed, fpow, 61)
FLOAT_ARITH_INSTR(Flog, FlogImmed, flog, 62)

instr(writeflags) Cmp cmp op:IMM, cc:IMM, a:REG(r), c:REG(r) << d:IMM { @DEFAULT op=45, b=QUARK_COND(%op, %cc); }
instr(writeflags) Cmp cmp op:IMM, cc:IMM, a:REG(r), i:IMM { @IMM11 op=45, b=QUARK_COND(%op, %cc); }
instr(writeflags) Icmp icmp op:IMM, cc:IMM, a:REG(r), c:REG(r) << d:IMM { @DEFAULT op=46, b=QUARK_COND(%op, %cc); }
instr(writeflags) Icmp icmp op:IMM, cc:IMM, a:REG(r), i:IMM { @IMM11 op=46, b=QUARK_COND(%op, %cc); }
instr(writeflags) Fcmp fcmp op:IMM, cc:IMM, a:REG(r), c:REG(r) { @DEFAULT op=47, b=QUARK_COND(%op, %cc); }
instr(writeflags) FcmpImmed fcmp op:IMM, cc:IMM, a:REG(r), i:IMM { @IMM11 op=47, b=QUARK_COND(%op, %cc); }
instr(readflags, writeflags) CondCmp cmp testcc:IMM = testval:IMM, op:IMM, cc:IMM, a:REG(r), c:REG(r) << d:IMM
{
	if (%testval)
		@DEFAULT cond=QUARK_IF_TRUE(%testcc), op=45, b=QUARK_COND(%op, %cc);
	else
		@DEFAULT cond=QUARK_IF_FALSE(%testcc), op=45, b=QUARK_COND(%op, %cc);
}
instr(readflags, writeflags) CondCmp cmp testcc:IMM = testval:IMM, op:IMM, cc:IMM, a:REG(r), i:IMM
{
	if (%testval)
		@IMM11 cond=QUARK_IF_TRUE(%testcc), op=45, b=QUARK_COND(%op, %cc);
	else
		@IMM11 cond=QUARK_IF_FALSE(%testcc), op=45, b=QUARK_COND(%op, %cc);
}
instr(readflags, writeflags) CondIcmp icmp testcc:IMM = testval:IMM, op:IMM, cc:IMM, a:REG(r), c:REG(r) << d:IMM
{
	if (%testval)
		@DEFAULT cond=QUARK_IF_TRUE(%testcc), op=46, b=QUARK_COND(%op, %cc);
	else
		@DEFAULT cond=QUARK_IF_FALSE(%testcc), op=46, b=QUARK_COND(%op, %cc);
}
instr(readflags, writeflags) CondIcmp icmp testcc:IMM = testval:IMM, op:IMM, cc:IMM, a:REG(r), i:IMM
{
	if (%testval)
		@IMM11 cond=QUARK_IF_TRUE(%testcc), op=46, b=QUARK_COND(%op, %cc);
	else
		@IMM11 cond=QUARK_IF_FALSE(%testcc), op=46, b=QUARK_COND(%op, %cc);
}

instr(copy) Mov mov a:REG(w), c:REG(r) { @DEFAULT op=31, b=0, d=0; } update
{
	// Eliminate mov instructions that have the same source and destination
	if (%a == %c)
		return true;
	return false;
}

instr MovShift mov a:REG(w), c:REG(r) << d:IMM { @DEFAULT op=31, b=0; }
instr MovImmed mov a:REG(w), i:IMM { @IMM11 op=31, b=0; }
instr Xchg xchg a:REG(rw), c:REG(rw) { @DEFAULT op=31, b=1; }
instr Sxb sxb a:REG(w), c:REG(r) { @DEFAULT op=31, b=2; }
instr Sxh sxh a:REG(w), c:REG(r) { @DEFAULT op=31, b=3; }
instr Swaph swaph a:REG(w), c:REG(r) { @DEFAULT op=31, b=4; }
instr Swapw swapw a:REG(w), c:REG(r) { @DEFAULT op=31, b=5; }
instr Neg neg a:REG(w), c:REG(r) { @DEFAULT op=31, b=8; }
instr Not not a:REG(w), c:REG(r) { @DEFAULT op=31, b=9; }
instr Zxb zxb a:REG(w), c:REG(r) { @DEFAULT op=31, b=10; }
instr Zxh zxh a:REG(w), c:REG(r) { @DEFAULT op=31, b=11; }
instr LoadCR ldcr a:REG(w) { @DEFAULT op=31, b=14; }
instr StoreCR stcr a:REG(r) { @DEFAULT op=31, b=15; }
instr(writeflags) SetCC setcc a:IMM { @DEFAULT op=31, b=24; }
instr(writeflags) ClrCC clrcc a:IMM { @DEFAULT op=31, b=25; }
instr(readflags, writeflags) NotCC notcc a:IMM, c:IMM { @DEFAULT op=31, b=26; }
instr(readflags, writeflags) MovCC movcc a:IMM, c:IMM { @DEFAULT op=31, b=27; }
instr(readflags, writeflags) AndCC andcc a:IMM, c:IMM, d:IMM { @DEFAULT op=31, b=28; }
instr(readflags, writeflags) OrCC orcc a:IMM, c:IMM, d:IMM { @DEFAULT op=31, b=29; }
instr(readflags, writeflags) XorCC xorcc a:IMM, c:IMM, d:IMM { @DEFAULT op=31, b=30; }
instr Breakpoint bp { @DEFAULT op=31, b=31; }

instr LoadFI ldfi a:REG(w), c:REG(r) << d:IMM { @DEFAULT op=63, b=0; }
instr LoadFI ldfi a:REG(w), i:IMM { @IMM11 op=63, b=0; }
instr StoreFI stfi a:REG(w), c:REG(r) { @DEFAULT op=63, b=1; }
instr LoadPi fldpi a:REG(w) { @DEFAULT op=63, b=2; }
instr LoadE flde a:REG(w) { @DEFAULT op=63, b=3; }
instr EtoXReg fex a:REG(w), c:REG(r) { @DEFAULT op=63, b=4; }
instr EtoXImmed fex a:REG(w), i:IMM { @IMM11 op=63, b=4; }
instr TwoToXReg f2x a:REG(w), c:REG(r) { @DEFAULT op=63, b=5; }
instr TwoToXImmed f2x a:REG(w), i:IMM { @IMM11 op=63, b=5; }
instr TenToXReg f10x a:REG(w), c:REG(r) { @DEFAULT op=63, b=6; }
instr TenToXImmed f10x a:REG(w), i:IMM { @IMM11 op=63, b=6; }
instr Sqrt fsqrt a:REG(w), c:REG(r) { @DEFAULT op=63, b=8; }
instr SqrtImmed fsqrt a:REG(w), i:IMM { @IMM11 op=63, b=8; }
instr Recip frcp a:REG(w), c:REG(r) { @DEFAULT op=63, b=9; }
instr RecipImmed frcp a:REG(w), i:IMM { @IMM11 op=63, b=9; }
instr RecipSqrt frsqrt a:REG(w), c:REG(r) { @DEFAULT op=63, b=10; }
instr RecipSqrtImmed frsqrt a:REG(w), i:IMM { @IMM11 op=63, b=10; }
instr Fneg fneg a:REG(w), c:REG(r) { @DEFAULT op=63, b=11; }
instr Fsin fsin a:REG(w), c:REG(r) { @DEFAULT op=63, b=12; }
instr Fcos fcos a:REG(w), c:REG(r) { @DEFAULT op=63, b=13; }
instr Ftan ftan a:REG(w), c:REG(r) { @DEFAULT op=63, b=14; }
instr Floor ffloor a:REG(w), c:REG(r) { @DEFAULT op=63, b=15; }
instr Fasin fasin a:REG(w), c:REG(r) { @DEFAULT op=63, b=16; }
instr Facos facos a:REG(w), c:REG(r) { @DEFAULT op=63, b=17; }
instr Fatan fatan a:REG(w), c:REG(r) { @DEFAULT op=63, b=18; }
instr Ceil fceil a:REG(w), c:REG(r) { @DEFAULT op=63, b=19; }
instr Fsinh fsinh a:REG(w), c:REG(r) { @DEFAULT op=63, b=20; }
instr Fcosh fcosh a:REG(w), c:REG(r) { @DEFAULT op=63, b=21; }
instr Ftanh ftanh a:REG(w), c:REG(r) { @DEFAULT op=63, b=22; }
instr Round fround a:REG(w), c:REG(r) { @DEFAULT op=63, b=23; }
instr Fasinh fasinh a:REG(w), c:REG(r) { @DEFAULT op=63, b=24; }
instr Facosh facosh a:REG(w), c:REG(r) { @DEFAULT op=63, b=25; }
instr Fatanh fatanh a:REG(w), c:REG(r) { @DEFAULT op=63, b=26; }
instr Fabs fabs a:REG(w), c:REG(r) { @DEFAULT op=63, b=27; }
instr Fln fln a:REG(w), c:REG(r) { @DEFAULT op=63, b=28; }
instr FlnImmed fln a:REG(w), i:IMM { @IMM11 op=63, b=28; }
instr Flog2 flog2 a:REG(w), c:REG(r) { @DEFAULT op=63, b=29; }
instr Flog2Immed flog2 a:REG(w), i:IMM { @IMM11 op=63, b=29; }
instr Flog10 flog10 a:REG(w), c:REG(r) { @DEFAULT op=63, b=30; }
instr Flog10Immed flog10 a:REG(w), i:IMM { @IMM11 op=63, b=30; }
instr Fmov fmov a:REG(w), c:REG(r) { @DEFAULT op=63, b=31; } update
{
	// Eliminate fmov instructions that have the same source and destination
	if (%a == %c)
		return true;
	return false;
}

instr FmovImmed fmov a:REG(w), i:IMM { @IMM11 op=63, b=31; }

instr SaveCalleeSavedRegs saveregs {} update
{
	vector<uint32_t> clobbered = func->GetClobberedCalleeSavedRegisters();
	uint32_t min = 29;
	set<uint32_t> fpu;
	for (vector<uint32_t>::iterator i = clobbered.begin(); i != clobbered.end(); i++)
	{
		uint32_t reg = (*i) & 63;
		if (reg >= 32)
			fpu.insert(reg & 31);
		else if (reg < min)
			min = reg;
	}

	// TODO: Support non-default stack pointer
	if (settings.stackGrowsUp)
	{
		for (vector<uint32_t>::iterator i = clobbered.begin(); i != clobbered.end(); i++)
			@StoreUpdate32 SYMREG_NATIVE_REG(*i), SYMREG_NATIVE_REG(0), 4;
		for (uint32_t i = 0; i < 32; i++)
		{
			if (fpu.count(i) != 0)
				@StoreUpdateFD SYMREG_FPU_REG(i), SYMREG_NATIVE_REG(0), 8;
		}
	}
	else
	{
		@StoreMultipleUpdate SYMREG_NATIVE_REG(min), SYMREG_NATIVE_REG(0), ((int32_t)min - 31) * 4;
		for (uint32_t i = 0; i < 32; i++)
		{
			if (fpu.count(i) != 0)
				@StoreUpdateFD SYMREG_FPU_REG(i), SYMREG_NATIVE_REG(0), -8;
		}
	}

	return true;
}

instr RestoreCalleeSavedRegs restoreregs {} update
{
	vector<uint32_t> clobbered = func->GetClobberedCalleeSavedRegisters();
	uint32_t min = 29;
	set<uint32_t> fpu;
	uint32_t stackSize = 0;
	for (vector<uint32_t>::iterator i = clobbered.begin(); i != clobbered.end(); i++)
	{
		uint32_t reg = (*i) & 63;
		if (reg >= 32)
		{
			fpu.insert(reg & 31);
			stackSize += 8;
		}
		else if (reg < min)
		{
			min = reg;
			if (settings.stackGrowsUp)
				stackSize += 4;
		}
	}

	// TODO: Support non-default stack pointer
	int32_t offset = 0;
	if (settings.stackGrowsUp)
	{
		for (vector<uint32_t>::iterator i = clobbered.begin(); i != clobbered.end(); i++, offset += 4)
			@Load32 SYMREG_NATIVE_REG(*i), SYMREG_NATIVE_REG(0), -stackSize + offset;
		for (uint32_t i = 0; i < 32; i++)
		{
			if (fpu.count(31 - i) != 0)
			{
				@LoadFD SYMREG_FPU_REG(31 - i), SYMREG_NATIVE_REG(0), -stackSize + offset;
				offset += 8;
			}
		}
		if (stackSize != 0)
			@Sub SYMREG_NATIVE_REG(0), SYMREG_NATIVE_REG(0), stackSize;
	}
	else
	{
		for (uint32_t i = 0; i < 32; i++)
		{
			if (fpu.count(31 - i) != 0)
			{
				@LoadFD SYMREG_FPU_REG(31 - i), SYMREG_NATIVE_REG(0), offset;
				offset += 8;
			}
		}
		if (stackSize != 0)
			@Add SYMREG_NATIVE_REG(0), SYMREG_NATIVE_REG(0), stackSize;
		@LoadMultipleUpdate SYMREG_NATIVE_REG(min), SYMREG_NATIVE_REG(0), 0;
	}

	return true;
}

instr(writeflags) AntiDisassembly antidisasm temp:TEMP
{
	int32_t a, b, cc, offset;
	cc = rand() & 3;
	offset = rand() & 0x7f;
	if (rand() & 1)
		offset = -offset;

	if (rand() & 1)
	{
		a = rand() & 0x3ff;
		@IMM17 op=20, a=%temp, i=a; // ldi
		@IMM11 op=24, a=%temp, b=%temp, i=-a; // add
		@IMM11 op=45, a=%temp, b=QUARK_COND(QUARK_COND_NE, cc), i=0; // cmp
		@IMM22 cond=QUARK_IF_TRUE(cc), op=22, i=offset; // jmp
	}
	else
	{
		a = rand() & 0x3ff;
		b = rand() & 0x3ff;
		if (rand() & 1)
			a = -a;
		if (rand() & 1)
			b = -b;
		@IMM17 op=20, a=%temp, i=a; // ldi
		@IMM11 op=38, a=%temp, b=%temp, i=b; // xor
		@IMM11 op=46, a=%temp, b=QUARK_COND(((a ^ b) & 0x80000000) ? QUARK_COND_GE : QUARK_COND_LT, cc), i=0; // icmp
		@IMM22 cond=QUARK_IF_TRUE(cc), op=22, i=offset; // jmp
	}
}

// Data flow pseudo-instructions
instr RegParam regparam regs:REGLIST(w) {} update { return true; }
instr SymReturn symreturn low:REG(r) high:REG(r) {} update { return true; }

src:IMM17 => dest:IREG { @LoadImm %dest, %src; }
src:IMM => dest:IREG { @LoadImm %dest, %src & 0xffff; @LoadImmHigh %dest, (%src >> 16) & 0xffff; }
src:IMM17 => dest:IREG64 { @LoadImm %dest:low, %src; @LoadImm %dest:high, %src >> 32; }
src:IMM => dest:IREG64
{
	@LoadImm %dest:low, %src & 0xffff;
	@LoadImmHigh %dest:low, (%src >> 16) & 0xffff;
	@LoadImm %dest:high, (%src >> 32) & 0xffff;
	@LoadImmHigh %dest:high, %src >> 48;
}

src:IRESULT => dest:IREG(S8) { @Sxb %dest, %src; }
src:IRESULT => dest:IREG(U8) { @Zxb %dest, %src; }
src:IRESULT => dest:IREG(S16) { @Sxh %dest, %src; }
src:IRESULT => dest:IREG(U16) { @Zxh %dest, %src; }
src:IRESULT => dest:IREG(32) {}

func:FUNCTION => dest:IREG, temp:IREG { @AddBlock %dest, SYMREG_IP, %func, %func->GetIL()[0], %temp; }

assign dest:IREG src:IMM { @LoadImm %dest, (%src & 0xffff); @LoadImmHigh %dest, (%src >> 16); }
assign dest:IREG src:IREG { @Mov %dest, %src; }
assign dest:IREG src:IMM17 { @LoadImm %dest, %src; }
assign dest:IREG src:IMM { @LoadImm %dest, (%src & 0xffff); @LoadImmHigh %dest, (%src >> 16); }
assign dest:FREG src:FREG { @Fmov %dest, %src; }
assign dest:FREG src:IMM { @FmovImmed %dest, %src; }
assign dest:IREG64 src:IREG64 { @Mov %dest:low, %src:low; @Mov %dest:high, %src:high; }

load(S8) base:IREG => dest:IREG { @LoadSX8 %dest, %base, 0; }
load(S8) add base:IREG ofs:IREG => dest:IREG { @LoadSX8 %dest, %base, %ofs, 0; }
load(S8) add base:IREG ofs:IMM11 => dest:IREG { @LoadSX8 %dest, %base, %ofs; }
load(S8) add base:IREG shl ofs:IREG shift:IMM => dest:IREG { @LoadSX8 %dest, %base, %ofs, %shift; }
load(U8) base:IREG => dest:IREG { @Load8 %dest, %base, 0; }
load(U8) add base:IREG ofs:IREG => dest:IREG { @Load8 %dest, %base, %ofs, 0; }
load(U8) add base:IREG ofs:IMM11 => dest:IREG { @Load8 %dest, %base, %ofs; }
load(U8) add base:IREG shl ofs:IREG shift:IMM => dest:IREG { @Load8 %dest, %base, %ofs, %shift; }
load(S16) base:IREG => dest:IREG { @LoadSX16 %dest, %base, 0; }
load(S16) add base:IREG ofs:IREG => dest:IREG { @LoadSX16 %dest, %base, %ofs, 0; }
load(S16) add base:IREG ofs:IMM11 => dest:IREG { @LoadSX16 %dest, %base, %ofs; }
load(S16) add base:IREG shl ofs:IREG shift:IMM => dest:IREG { @LoadSX16 %dest, %base, %ofs, %shift; }
load(U16) base:IREG => dest:IREG { @Load16 %dest, %base, 0; }
load(U16) add base:IREG ofs:IREG => dest:IREG { @Load16 %dest, %base, %ofs, 0; }
load(U16) add base:IREG ofs:IMM11 => dest:IREG { @Load16 %dest, %base, %ofs; }
load(U16) add base:IREG shl ofs:IREG shift:IMM => dest:IREG { @Load16 %dest, %base, %ofs, %shift; }
load(32) base:IREG => dest:IREG { @Load32 %dest, %base, 0; }
load(32) add base:IREG ofs:IREG => dest:IREG { @Load32 %dest, %base, %ofs, 0; }
load(32) add base:IREG ofs:IMM11 => dest:IREG { @Load32 %dest, %base, %ofs; }
load(32) add base:IREG shl ofs:IREG shift:IMM => dest:IREG { @Load32 %dest, %base, %ofs, %shift; }
load(64) base:IREG => dest:IREG64 { @Load32 %dest:low, %base, 0; @Load32 %dest:high, %base, 4; }
load(64) add base:IREG ofs:IMM11M4 => dest:IREG64 { @Load32 %dest:low, %base, %ofs; @Load32 %dest:high, %base, %ofs + 4; }
load ref src:STACKVAR(S8) => dest:IREG { @LoadStackSX8 %dest, %src; }
load ref src:STACKVAR(U8) => dest:IREG { @LoadStack8 %dest, %src; }
load ref src:STACKVAR(S16) => dest:IREG { @LoadStackSX16 %dest, %src; }
load ref src:STACKVAR(U16) => dest:IREG { @LoadStack16 %dest, %src; }
load ref src:STACKVAR(32) => dest:IREG { @LoadStack32 %dest, %src; }
load ref src:STACKVAR(64) => dest:IREG64 { @LoadStack32 %dest:low, %src:0; @LoadStack32 %dest:high, %src:4; }
load ref src:STACKVAR(F32) => dest:FREG { @LoadStackFS %dest, %src; }
load ref src:STACKVAR(F64) => dest:FREG { @LoadStackFD %dest, %src; }
load ref src:GLOBALVAR(S8) => dest:IREG { @LoadGlobalSX8 %dest, %src; }
load ref src:GLOBALVAR(U8) => dest:IREG { @LoadGlobal8 %dest, %src; }
load ref src:GLOBALVAR(S16) => dest:IREG { @LoadGlobalSX16 %dest, %src; }
load ref src:GLOBALVAR(U16) => dest:IREG { @LoadGlobal16 %dest, %src; }
load ref src:GLOBALVAR(32) => dest:IREG { @LoadGlobal32 %dest, %src; }
load ref src:GLOBALVAR(64) => dest:IREG64 { @LoadGlobal32 %dest:low, %src:0; @LoadGlobal32 %dest:high, %src:4; }
load ref src:GLOBALVAR(F32) => dest:FREG { @LoadGlobalFS %dest, %src; }
load ref src:GLOBALVAR(F64) => dest:FREG { @LoadGlobalFD %dest, %src; }

store(8) base:IREG src:IREG { @Store8 %src, %base, 0; }
store(8) add base:IREG ofs:IREG src:IREG { @Store8 %src, %base, %ofs, 0; }
store(8) add base:IREG ofs:IMM11 src:IREG { @Store8 %src, %base, %ofs; }
store(8) add base:IREG shl ofs:IREG shift:IMM src:IREG { @Store8 %src, %base, %ofs, %shift; }
store(16) base:IREG src:IREG { @Store16 %src, %base, 0; }
store(16) add base:IREG ofs:IREG src:IREG { @Store16 %src, %base, %ofs, 0; }
store(16) add base:IREG ofs:IMM11 src:IREG { @Store16 %src, %base, %ofs; }
store(16) add base:IREG shl ofs:IREG shift:IMM src:IREG { @Store16 %src, %base, %ofs, %shift; }
store(32) base:IREG src:IREG { @Store32 %src, %base, 0; }
store(32) add base:IREG ofs:IREG src:IREG { @Store32 %src, %base, %ofs, 0; }
store(32) add base:IREG ofs:IMM11 src:IREG { @Store32 %src, %base, %ofs; }
store(32) add base:IREG shl ofs:IREG shift:IMM src:IREG { @Store32 %src, %base, %ofs, %shift; }
store(64) base:IREG src:IREG64 { @Store32 %src:low, %base, 0; @Store32 %src:high, %base, 4; }
store ref dest:STACKVAR(8) src:IREG { @StoreStack8 %src, %dest; }
store ref dest:STACKVAR(16) src:IREG { @StoreStack16 %src, %dest; }
store ref dest:STACKVAR(32) src:IREG { @StoreStack32 %src, %dest; }
store ref dest:STACKVAR(64) src:IREG64 { @StoreStack32 %src:low, %dest:0; @StoreStack32 %src:high, %dest:4; }
store ref dest:STACKVAR(F32) src:FREG { @StoreStackFS %src, %dest; }
store ref dest:STACKVAR(F64) src:FREG { @StoreStackFD %src, %dest; }
store ref dest:GLOBALVAR(8) src:IREG { @StoreGlobal8 %src, %dest; }
store ref dest:GLOBALVAR(16) src:IREG { @StoreGlobal16 %src, %dest; }
store ref dest:GLOBALVAR(32) src:IREG { @StoreGlobal32 %src, %dest; }
store ref dest:GLOBALVAR(64) src:IREG64 { @StoreGlobal32 %src:low, %dest:0; @StoreGlobal32 %src:high, %dest:4; }
store ref dest:GLOBALVAR(F32) src:FREG { @StoreGlobalFS %src, %dest; }
store ref dest:GLOBALVAR(F64) src:FREG { @StoreGlobalFD %src, %dest; }

ref base:STACKVAR => dest:IREG { @AddStack %dest, %base; }
ref base:GLOBALVAR => dest:IREG { @AddGlobal %dest, %base; }

add a:IREG b:IREG => dest:IRESULT { @Add %dest, %a, %b, 0; }
add a:IREG shl b:IREG c:IMM => dest:IRESULT { @Add %dest, %a, %b, %c; }
add a:IREG b:IMM11 => dest:IRESULT { @Add %dest, %a, %b; }
add a:IREG64 b:IREG64 => dest:IREG64 { @ClrCC 3; @Addx %dest:low, %a:low, %b:low, 0; @Addx %dest:high, %a:high, %b:high, 0; }
add a:IREG64 b:IMM11 => dest:IREG64 { @ClrCC 3; @Addx %dest:low, %a:low, %b, 0; @Addx %dest:high, %a:high, 0; }
add a:FREG b:FREG => dest:FREG { @Fadd %dest, %a, %b; }
add a:FREG b:IMM => dest:FREG { @FaddImmed %dest, %a, %b; }

sub a:IREG b:IREG => dest:IRESULT { @Sub %dest, %a, %b, 0; }
sub a:IREG shl b:IREG c:IMM => dest:IRESULT { @Sub %dest, %a, %b, %c; }
sub a:IREG b:IMM11 => dest:IRESULT { @Sub %dest, %a, %b; }
sub a:IREG64 b:IREG64 => dest:IREG64 { @ClrCC 3; @Subx %dest:low, %a:low, %b:low, 0; @Subx %dest:high, %a:high, %b:high, 0; }
sub a:IREG64 b:IMM11 => dest:IREG64 { @ClrCC 3; @Subx %dest:low, %a:low, %b, 0; @Subx %dest:high, %a:high, 0; }
sub a:FREG b:FREG => dest:FREG { @Fsub %dest, %a, %b; }
sub a:FREG b:IMM => dest:FREG { @FsubImmed %dest, %a, %b; }

#define MUL_INSTR(op) \
op a:IREG b:IREG => dest:IRESULT { @Mul %dest, %a, %b, 0; } \
op a:IREG shl b:IREG c:IMM => dest:IRESULT { @Mul %dest, %a, %b, %c; } \
op a:IREG b:IMM11 => dest:IRESULT { @Mul %dest, %a, %b; } \
op a:IREG64 b:IREG64 => dest:IREG64, temp:IREG \
{ \
	@Mulx %dest:high, %dest:low, %a:low, %b:low; \
	@Mul %temp, %a:low, %b:high, 0; \
	@Add %dest:high, %dest:high, %temp, 0; \
	@Mul %temp, %a:high, %b:low, 0; \
	@Add %dest:high, %dest:high, %temp, 0; \
}
MUL_INSTR(smul)
MUL_INSTR(umul)
smul a:FREG b:FREG => dest:FREG { @Fmul %dest, %a, %b; }
smul a:FREG b:IMM => dest:FREG { @FmulImmed %dest, %a, %b; }

sdiv a:IREG b:IREG => dest:IRESULT { @Idiv %dest, %a, %b, 0; }
sdiv a:IREG shl b:IREG c:IMM => dest:IRESULT { @Idiv %dest, %a, %b, %c; }
sdiv a:IREG b:IMM11 => dest:IRESULT { @Idiv %dest, %a, %b; }
sdiv a:FREG b:FREG => dest:FREG { @Fdiv %dest, %a, %b; }
sdiv a:FREG b:IMM => dest:FREG { @FdivImmed %dest, %a, %b; }

udiv a:IREG b:IREG => dest:IRESULT { @Div %dest, %a, %b, 0; }
udiv a:IREG shl b:IREG c:IMM => dest:IRESULT { @Div %dest, %a, %b, %c; }
udiv a:IREG b:IMM11 => dest:IRESULT { @Div %dest, %a, %b; }

smod a:IREG b:IREG => dest:IRESULT { @Imod %dest, %a, %b, 0; }
smod a:IREG shl b:IREG c:IMM => dest:IRESULT { @Imod %dest, %a, %b, %c; }
smod a:IREG b:IMM11 => dest:IRESULT { @Imod %dest, %a, %b; }
smod a:FREG b:FREG => dest:FREG { @Fmod %dest, %a, %b; }
smod a:FREG b:IMM => dest:FREG { @FmodImmed %dest, %a, %b; }

umod a:IREG b:IREG => dest:IRESULT { @Mod %dest, %a, %b, 0; }
umod a:IREG shl b:IREG c:IMM => dest:IRESULT { @Mod %dest, %a, %b, %c; }
umod a:IREG b:IMM11 => dest:IRESULT { @Mod %dest, %a, %b; }

#define BITWISE_INSTR(op, instr) \
op a:IREG b:IREG => dest:IREG { instr %dest, %a, %b, 0; } \
op a:IREG shl b:IREG c:IMM => dest:IREG { instr %dest, %a, %b, %c; } \
op a:IREG b:IMM11 => dest:IREG { instr %dest, %a, %b; } \
op a:IREG64 b:IREG64 => dest:IREG64 { instr %dest:low, %a:low, %b:low, 0; instr %dest:high, %a:high, %b:high, 0; } \
op a:IREG64 b:IMM11 => dest:IREG64 { instr %dest:low, %a:low, (int32_t)%b; instr %dest:high, %a:high, (int32_t)(%b >> 32); }
BITWISE_INSTR(and, @And)
BITWISE_INSTR(or, @Or)
BITWISE_INSTR(xor, @Xor)

#define SHIFT_INSTR(op, instr) \
op a:IREG b:IREG => dest:IREG { instr %dest, %a, %b, 0; } \
op a:IREG b:IMM => dest:IREG { instr %dest, %a, %b; }
SHIFT_INSTR(shl, @Shl)
SHIFT_INSTR(shr, @Shr)
SHIFT_INSTR(sar, @Sar)

neg src:IREG => dest:IRESULT { @Neg %dest, %src; }
neg src:FREG => dest:FREG { @Fneg %dest, %src; }
neg src:IREG64 => dest:IREG64
{
	@Not %dest:low, %src:low;
	@Not %dest:high, %src:high;
	@ClrCC 3;
	@Addx %dest:low, %dest:low, 1;
	@Addx %dest:high, %dest:high, 0;
}

not src:IREG => dest:IRESULT { @Not %dest, %src; }
not src:IREG64 => dest:IREG64 { @Not %dest:low, %src:low; @Not %dest:high, %src:high; }

function void ConditionalJump(SymInstrBlock* out, TreeBlock* block, int cond, bool value)
{
	@CondJump cond, value ? 1 : 0, m_func, block->GetSource();
}


function void UnconditionalJump(SymInstrBlock* out, TreeBlock* block, bool canOmit = true)
{
	if (canOmit && (!m_settings.pad) && (block->GetSource()->GetGlobalIndex() == (m_currentBlock->GetSource()->GetGlobalIndex() + 1)))
	{
		// The destination block is the one just after the current one, just fall through
		return;
	}

	@Jump m_func, block->GetSource();
}

#define COND_JUMP \
	ConditionalJump(out, %t, 0, true); \
	UnconditionalJump(out, %f)

iftrue src:IREG t:BLOCK f:BLOCK { @Cmp QUARK_COND_NE, 0, %src, 0; COND_JUMP; }
iftrue src:FREG t:BLOCK f:BLOCK { @FcmpImmed QUARK_COND_NE, 0, %src, 0; COND_JUMP; }
iftrue src:IREG64 t:BLOCK f:BLOCK
{
	@Cmp QUARK_COND_NE, 0, %src:low, 0;
	@Cmp QUARK_COND_NE, 1, %src:high, 0;
	@OrCC 0, 0, 1;
	COND_JUMP;
}

#define COND_COMPARE(op, cond, instr) \
op a:IREG b:IREG t:BLOCK f:BLOCK { instr cond, 0, %a, %b, 0; COND_JUMP; } \
op a:IREG shl b:IREG c:IMM t:BLOCK f:BLOCK { instr cond, 0, %a, %b, %c; COND_JUMP; } \
op a:IREG b:IMM11 t:BLOCK f:BLOCK { instr cond, 0, %a, %b; COND_JUMP; } \
op a:FREG b:FREG t:BLOCK f:BLOCK { @Fcmp cond, 0, %a, %b; COND_JUMP; } \
op a:IREG64 b:IREG64 t:BLOCK f:BLOCK \
{ \
	instr QUARK_COND_LT, 0, %a:high, %b:high, 0; \
	instr QUARK_COND_EQ, 1, %a:high, %b:high, 0; \
	@CondCmp 1, 1, cond, 0, %a:low, %b:low, 0; \
	COND_JUMP; \
} \
op a:IREG64 b:IMM11 t:BLOCK f:BLOCK \
{ \
	instr QUARK_COND_LT, 0, %a:high, (int32_t)(%b >> 32); \
	instr QUARK_COND_EQ, 1, %a:high, (int32_t)(%b >> 32); \
	@CondCmp 1, 1, cond, 0, %a:low, (int32_t)%b; \
	COND_JUMP; \
}
COND_COMPARE(ifslt, QUARK_COND_LT, @Icmp)
COND_COMPARE(ifult, QUARK_COND_LT, @Cmp)
COND_COMPARE(ifsle, QUARK_COND_LE, @Icmp)
COND_COMPARE(ifule, QUARK_COND_LE, @Cmp)

ife a:IREG b:IREG t:BLOCK f:BLOCK { @Cmp QUARK_COND_EQ, 0, %a, %b, 0; COND_JUMP; }
ife a:IREG shl b:IREG c:IMM t:BLOCK f:BLOCK { @Cmp QUARK_COND_EQ, 0, %a, %b, %c; COND_JUMP; }
ife a:IREG b:IMM11 t:BLOCK f:BLOCK { @Cmp QUARK_COND_EQ, 0, %a, %b; COND_JUMP; }
ife a:FREG b:FREG t:BLOCK f:BLOCK { @Fcmp QUARK_COND_EQ, 0, %a, %b; COND_JUMP; }
ife a:IREG64 b:IREG64 t:BLOCK f:BLOCK
{
	@Cmp QUARK_COND_EQ, 0, %a:low, %b:low, 0;
	@Cmp QUARK_COND_EQ, 1, %a:high, %b:high, 0;
	@AndCC 0, 0, 1;
	COND_JUMP;
}
ife a:IREG64 b:IMM11 t:BLOCK f:BLOCK
{
	@Cmp QUARK_COND_EQ, 0, %a:low, (int32_t)%b;
	@Cmp QUARK_COND_EQ, 1, %a:high, (int32_t)(%b >> 32);
	@AndCC 0, 0, 1;
	COND_JUMP;
}

goto dest:BLOCK { UnconditionalJump(out, %dest); }
goto dest:IREG { @Mov SYMREG_IP, %dest; }
goto shl dest:IREG c:IMM { @MovShift SYMREG_IP, %dest, %c; }
goto dest:IMM11 { @LoadImm SYMREG_IP, %dest; }

function void AdjustStackAfterCall(SymInstrBlock* out, uint32_t stackAdjust)
{
	if (stackAdjust != 0)
	{
		if (m_settings.stackGrowsUp)
			@Sub SYMREG_SP, SYMREG_SP, stackAdjust;
		else
			@Add SYMREG_SP, SYMREG_SP, stackAdjust;
	}
}

call func:FUNCTION reads:INPUT stackAdjust:IMM11 => dest:INTEGER_RETURN_VALUE
{
	@Call %func, %func->GetIL()[0], %dest, SYMREG_NONE, %reads;
	AdjustStackAfterCall(out, (uint32_t)%stackAdjust);
}
call func:FUNCTION reads:INPUT stackAdjust:IMM11 => dest:INTEGER_RETURN_VALUE_64
{
	@Call %func, %func->GetIL()[0], %dest:low, %dest:high, %reads;
	AdjustStackAfterCall(out, (uint32_t)%stackAdjust);
}
call func:FUNCTION reads:INPUT stackAdjust:IMM11 => dest:FLOAT_RETURN_VALUE
{
	@Call %func, %func->GetIL()[0], %dest, SYMREG_NONE, %reads;
	AdjustStackAfterCall(out, (uint32_t)%stackAdjust);
}
callvoid func:FUNCTION reads:INPUT stackAdjust:IMM11
{
	@Call %func, %func->GetIL()[0], SYMREG_NONE, SYMREG_NONE, %reads;
	AdjustStackAfterCall(out, (uint32_t)%stackAdjust);
}
call func:IREG reads:INPUT stackAdjust:IMM11 => dest:INTEGER_RETURN_VALUE
{
	@Call %func, %dest, SYMREG_NONE, %reads;
	AdjustStackAfterCall(out, (uint32_t)%stackAdjust);
}
call func:IREG reads:INPUT stackAdjust:IMM11 => dest:INTEGER_RETURN_VALUE_64
{
	@Call %func, %dest:low, %dest:high, %reads;
	AdjustStackAfterCall(out, (uint32_t)%stackAdjust);
}
call func:IREG reads:INPUT stackAdjust:IMM11 => dest:FLOAT_RETURN_VALUE
{
	@Call %func, %dest, SYMREG_NONE, %reads;
	AdjustStackAfterCall(out, (uint32_t)%stackAdjust);
}
callvoid func:IREG reads:INPUT stackAdjust:IMM11
{
	@Call %func, SYMREG_NONE, SYMREG_NONE, %reads;
	AdjustStackAfterCall(out, (uint32_t)%stackAdjust);
}

syscall (num:IMM11) reads:INPUT => dest:SYSCALL_RETURN
{
	vector<uint32_t> writes;
	writes.push_back(%dest);
	@SyscallImmed %num, writes, %reads;
}
syscall (num:IMM11) reads:INPUT => dest:SYSCALL_RETURN_64
{
	vector<uint32_t> writes;
	writes.push_back(%dest:low);
	writes.push_back(%dest:high);
	@SyscallImmed %num, writes, %reads;
}
syscallvoid (num:IMM11) reads:INPUT
{
	vector<uint32_t> writes;
	@SyscallImmed %num, writes, %reads;
}
syscall (num:IREG) reads:INPUT => dest:SYSCALL_RETURN
{
	vector<uint32_t> writes;
	writes.push_back(%dest);
	@SyscallReg %num, writes, %reads;
}
syscall (num:IREG) reads:INPUT => dest:SYSCALL_RETURN_64
{
	vector<uint32_t> writes;
	writes.push_back(%dest:low);
	writes.push_back(%dest:high);
	@SyscallReg %num, writes, %reads;
}
syscallvoid (num:IREG) reads:INPUT
{
	vector<uint32_t> writes;
	@SyscallReg %num, writes, %reads;
}

sconvert src:FREG => dest:IREG { @StoreFI %dest, %src; }
sconvert src:IREG => dest:FREG { @LoadFI %dest, %src; }
sconvert src:FREG => dest:FREG { @Fmov %dest, %src; }
sconvert src:IREG(8) => dest:IREG(16,32) { @Sxb %dest, %src; }
sconvert src:IREG(8) => dest:IREG64 { @Sxb %dest:low, %src; @Sar %dest:high, %dest:low, 31; }
uconvert src:IREG(8) => dest:IREG(16,32) { @Zxb %dest, %src; }
uconvert src:IREG(8) => dest:IREG64 { @Zxb %dest:low, %src; @LoadImm %dest:high, 0; }
sconvert src:IREG(16) => dest:IREG(32) { @Sxh %dest, %src; }
sconvert src:IREG(16) => dest:IREG64 { @Sxh %dest:low, %src; @Sar %dest:high, %dest:low, 31; }
uconvert src:IREG(16) => dest:IREG(32) { @Zxh %dest, %src; }
uconvert src:IREG(16) => dest:IREG64 { @Zxh %dest:low, %src; @LoadImm %dest:high, 0; }
sconvert src:IREG(32) => dest:IREG64 { @Mov %dest:low, %src; @Sar %dest:high, %dest:low, 31; }
uconvert src:IREG(32) => dest:IREG64 { @Mov %dest:low, %src; @LoadImm %dest:high, 0; }
sconvert src:IREG(16,32) => dest:IREG(8) { @Sxb %dest, %src; }
sconvert src:IREG64 => dest:IREG(8) { @Sxb %dest, %src:low; }
uconvert src:IREG(16,32) => dest:IREG(8) { @Zxb %dest, %src; }
uconvert src:IREG64 => dest:IREG(8) { @Zxb %dest, %src:low; }
sconvert src:IREG(32) => dest:IREG(16) { @Sxh %dest, %src; }
sconvert src:IREG64 => dest:IREG(16) { @Sxh %dest, %src:low; }
uconvert src:IREG(32) => dest:IREG(16) { @Zxh %dest, %src; }
uconvert src:IREG64 => dest:IREG(16) { @Zxh %dest, %src:low; }
sconvert src:IREG64 => dest:IREG(32) { @Mov %dest, %src:low; }
uconvert src:IREG64 => dest:IREG(32) { @Mov %dest, %src:low; }

function bool GenerateReturnVoid(SymInstrBlock* out)
{
	// Restore frame pointer (if present) and adjust stack
	if (m_framePointerEnabled)
	{
		@Mov SYMREG_SP, SYMREG_BP;
	}
	else
	{
		// TODO: Support frames without a frame pointer
		return false;
	}

	@RestoreCalleeSavedRegs;

	// Return to caller
	if (m_settings.encodePointers)
	{
		// Using encoded pointers, decode return address before returning
		uint32_t temp = TEMP_REGISTER(IREG);
		uint32_t scratch = TEMP_REGISTER(IREG);
		@LoadGlobal32 temp, SYMREG_IP, m_settings.encodePointerKey->GetDataSectionOffset(), scratch;
		@Xor SYMREG_LR, SYMREG_LR, temp, 0;
	}

	@Mov SYMREG_IP, SYMREG_LR;
	return true;
}

return src:IREG, retval:INTEGER_RETURN_VALUE { @Mov %retval, %src; GenerateReturnVoid(out); @SymReturn %retval, SYMREG_NONE; }
return src:FREG, retval:FLOAT_RETURN_VALUE { @Fmov %retval, %src; GenerateReturnVoid(out); @SymReturn %retval, SYMREG_NONE; }
return src:IREG64, retval:INTEGER_RETURN_VALUE_64
{
	@Mov %retval:low, %src:low;
	@Mov %retval:high, %src:high;
	GenerateReturnVoid(out);
	@SymReturn %retval:low, %retval:high;
}

returnvoid { GenerateReturnVoid(out); }

alloca size:IREG => result:IREG
{
	if (m_settings.stackGrowsUp)
	{
		@Add SYMREG_SP, SYMREG_SP, 4;
		@Mov %result, SYMREG_SP;
		@Add SYMREG_SP, SYMREG_SP, %size, 0;
		@And SYMREG_SP, SYMREG_SP, ~3;
	}
	else
	{
		@Sub SYMREG_SP, SYMREG_SP, %size, 0;
		@And SYMREG_SP, SYMREG_SP, ~3;
		@Mov %result, SYMREG_SP;
	}
}

alloca size:IMM11 => result:IREG
{
	if (m_settings.stackGrowsUp)
	{
		@Add SYMREG_SP, SYMREG_SP, 4;
		@Mov %result, SYMREG_SP;
		@Add SYMREG_SP, SYMREG_SP, %size & (~3);
	}
	else
	{
		@Sub SYMREG_SP, SYMREG_SP, (%size + 3) & (~3);
		@Mov %result, SYMREG_SP;
	}
}

vararg => result:IREG, temp:IREG { @AddStack %result, SYMREG_BP, m_varargStart, 0, %temp; }

byteswap src:IREG(16) => dest:IREG { @Swaph %dest, %src; }
byteswap src:IREG(32) => dest:IREG { @Swapw %dest, %src; }
byteswap src:IREG64 => dest:IREG64 { @Swapw %dest:low, %src:high; @Swapw %dest:high, %src:low; }

breakpoint { @Breakpoint; }

pow a:FREG b:FREG => dest:FREG { @Fpow %dest, %a, %b; }
pow a:FREG b:IMM11 => dest:FREG { @FpowImmed %dest, %a, %b; }
floor src:FREG => dest:FREG { @Floor %dest, %src; }
ceil src:FREG => dest:FREG { @Ceil %dest, %src; }

sqrt src:FREG => dest:FREG { @Sqrt %dest, %src; }
sqrt src:IMM11 => dest:FREG { @SqrtImmed %dest, %src; }
sin src:FREG => dest:FREG { @Fsin %dest, %src; }
cos src:FREG => dest:FREG { @Fcos %dest, %src; }
tan src:FREG => dest:FREG { @Ftan %dest, %src; }
asin src:FREG => dest:FREG { @Fasin %dest, %src; }
acos src:FREG => dest:FREG { @Facos %dest, %src; }
atan src:FREG => dest:FREG { @Fatan %dest, %src; }

push src:IREG
{
	if (m_settings.stackGrowsUp)
		@StoreUpdate32 %src, SYMREG_SP, 4;
	else
		@StoreUpdate32 %src, SYMREG_SP, -4;
}
push src:IREG64
{
	if (m_settings.stackGrowsUp)
	{
		@Store32 %src:low, SYMREG_SP, 4;
		@StoreUpdate32 %src:high, SYMREG_SP, 8;
	}
	else
	{
		@Store32 %src:high, SYMREG_SP, -4;
		@StoreUpdate32 %src:low, SYMREG_SP, -8;
	}
}
push src:FREG(F32)
{
	if (m_settings.stackGrowsUp)
		@StoreUpdateFS %src, SYMREG_SP, 4;
	else
		@StoreUpdateFS %src, SYMREG_SP, -4;
}
push src:FREG(F64)
{
	if (m_settings.stackGrowsUp)
		@StoreUpdateFD %src, SYMREG_SP, 8;
	else
		@StoreUpdateFD %src, SYMREG_SP, -8;
}

function void GenerateAntiDisassembly(SymInstrBlock* out)
{
	@AntiDisassembly TEMP_REGISTER(IREG);
}

function TreeNode* GenerateCall(TreeBlock* block, TreeNode* func, size_t fixedParams, const vector< Ref<TreeNode> >& params,
	TreeNodeType resultType)
{
	if (m_settings.encodePointers)
	{
		// FIXME: Symbolic representation of return address is not there yet
		return NULL;
	}

	// First try to place parameters in registers
	uint32_t intParamRegs[9] = {INTEGER_PARAM_0, INTEGER_PARAM_1, INTEGER_PARAM_2,
		INTEGER_PARAM_3, INTEGER_PARAM_4, INTEGER_PARAM_5, INTEGER_PARAM_6,
		INTEGER_PARAM_7, SYMREG_NONE};
	uint32_t floatParamRegs[9] = {FLOAT_PARAM_0, FLOAT_PARAM_1, FLOAT_PARAM_2,
		FLOAT_PARAM_3, FLOAT_PARAM_4, FLOAT_PARAM_5, FLOAT_PARAM_6,
		FLOAT_PARAM_7, SYMREG_NONE};
	uint32_t curIntParamReg = 0;
	uint32_t curFloatParamReg = 0;
	vector<bool> paramOnStack;
	Ref<TreeNode> input = new TreeNode(NODE_INPUT);

	for (size_t i = 0; i < params.size(); i++)
	{
		if (i >= fixedParams)
		{
			// Additional parameters to variable argument functions must be on stack
			paramOnStack.push_back(true);
			continue;
		}

		bool stackParam = false;
		if (params[i]->GetClass() == NODE_UNDEFINED)
		{
			// Parameter is undefined, skip it
			if ((params[i]->GetType() == NODETYPE_F32) || (params[i]->GetType() == NODETYPE_F64))
			{
				if (floatParamRegs[curFloatParamReg] == SYMREG_NONE)
					stackParam = true;
				else
					curFloatParamReg++;
			}
			else if ((params[i]->GetType() == NODETYPE_U64) || (params[i]->GetType() == NODETYPE_S64))
			{
				if ((intParamRegs[curIntParamReg] == SYMREG_NONE) || (intParamRegs[curIntParamReg + 1] == SYMREG_NONE))
					stackParam = true;
				else
					curIntParamReg += 2;
			}
			else
			{
				if (intParamRegs[curIntParamReg] == SYMREG_NONE)
					stackParam = true;
				else
					curIntParamReg++;
			}

			paramOnStack.push_back(stackParam);
			continue;
		}

		if ((params[i]->GetType() == NODETYPE_F32) || (params[i]->GetType() == NODETYPE_F64))
		{
			if (floatParamRegs[curFloatParamReg] == SYMREG_NONE)
				stackParam = true;
			else
			{
				uint32_t cls = floatParamRegs[curFloatParamReg++];
				uint32_t reg = m_symFunc->AddRegister(cls);
				input->AddChildNode(TreeNode::CreateRegNode(reg, cls, params[i]->GetType()));

				block->AddNode(TreeNode::CreateNode(NODE_ASSIGN, params[i]->GetType(), TreeNode::CreateRegNode(reg,
					cls, params[i]->GetType()), params[i]));
			}
		}
		else if ((params[i]->GetType() == NODETYPE_U64) || (params[i]->GetType() == NODETYPE_S64))
		{
			if ((intParamRegs[curIntParamReg] == SYMREG_NONE) || (intParamRegs[curIntParamReg + 1] == SYMREG_NONE))
				stackParam = true;
			else
			{
				uint32_t lowCls = intParamRegs[curIntParamReg++];
				uint32_t highCls = intParamRegs[curIntParamReg++];
				uint32_t lowReg = m_symFunc->AddRegister(lowCls);
				uint32_t highReg = m_symFunc->AddRegister(highCls);
				input->AddChildNode(TreeNode::CreateRegNode(lowReg, lowCls, NODETYPE_U32));
				input->AddChildNode(TreeNode::CreateRegNode(highReg, highCls, NODETYPE_U32));

				block->AddNode(TreeNode::CreateNode(NODE_ASSIGN, params[i]->GetType(), TreeNode::CreateLargeRegNode(lowReg, highReg,
					lowCls, highCls, params[i]->GetType()), params[i]));
			}
		}
		else
		{
			if (intParamRegs[curIntParamReg] == SYMREG_NONE)
				stackParam = true;
			else
			{
				uint32_t cls = intParamRegs[curIntParamReg++];
				uint32_t reg = m_symFunc->AddRegister(cls);
				input->AddChildNode(TreeNode::CreateRegNode(reg, cls, params[i]->GetType()));

				block->AddNode(TreeNode::CreateNode(NODE_ASSIGN, params[i]->GetType(), TreeNode::CreateRegNode(reg,
					cls, params[i]->GetType()), params[i]));
			}
		}

		paramOnStack.push_back(stackParam);
	}

	// Push parameters from right to left
	size_t pushSize = 0;
	for (int i = (int)params.size() - 1; i >= 0; i--)
	{
		if (!paramOnStack[i])
			continue;

		block->AddNode(TreeNode::CreateNode(NODE_PUSH, params[i]->GetType(), params[i]));

		if ((params[i]->GetType() == NODETYPE_U64) || (params[i]->GetType() == NODETYPE_S64) ||
			(params[i]->GetType() == NODETYPE_F64))
			pushSize += 8;
		else
			pushSize += 4;
	}

	return TreeNode::CreateNode((resultType == NODETYPE_UNDEFINED) ? NODE_CALLVOID : NODE_CALL, resultType, func, input,
		TreeNode::CreateImmediateNode(pushSize, NODETYPE_U32));
}

function TreeNode* GenerateSyscall(TreeBlock* block, TreeNode* num, const vector< Ref<TreeNode> >& params, TreeNodeType resultType)
{
	Ref<TreeNode> input = new TreeNode(NODE_INPUT);
	size_t regIndex = 0;
	const uint32_t paramClasses[8] = {SYSCALL_PARAM_0, SYSCALL_PARAM_1,
		SYSCALL_PARAM_2, SYSCALL_PARAM_3, SYSCALL_PARAM_4,
		SYSCALL_PARAM_5, SYSCALL_PARAM_6, SYSCALL_PARAM_7};
	for (vector< Ref<TreeNode> >::const_iterator i = params.begin(); i != params.end(); ++i)
	{
		if ((*i)->GetClass() == NODE_UNDEFINED)
		{
			regIndex++;
			if (((*i)->GetType() == NODETYPE_U64) || ((*i)->GetType() == NODETYPE_S64))
				regIndex++;
			if (regIndex > 8)
				return NULL;
			continue;
		}

		if (((*i)->GetType() == NODETYPE_U64) || ((*i)->GetType() == NODETYPE_S64))
		{
			if (regIndex > 6)
				return NULL;
			uint32_t reg = m_symFunc->AddRegister(paramClasses[regIndex]);
			uint32_t highReg = m_symFunc->AddRegister(paramClasses[regIndex + 1]);
			input->AddChildNode(TreeNode::CreateRegNode(reg, paramClasses[regIndex], NODETYPE_U32));
			input->AddChildNode(TreeNode::CreateRegNode(highReg, paramClasses[regIndex + 1], NODETYPE_U32));

			block->AddNode(TreeNode::CreateNode(NODE_ASSIGN, (*i)->GetType(), TreeNode::CreateLargeRegNode(reg, highReg,
				paramClasses[regIndex], paramClasses[regIndex + 1], (*i)->GetType()), *i));

			regIndex += 2;
		}
		else
		{
			if (regIndex > 7)
				return NULL;
			uint32_t reg = m_symFunc->AddRegister(paramClasses[regIndex]);
			input->AddChildNode(TreeNode::CreateRegNode(reg, paramClasses[regIndex], (*i)->GetType()));

			block->AddNode(TreeNode::CreateNode(NODE_ASSIGN, (*i)->GetType(), TreeNode::CreateRegNode(reg,
				paramClasses[regIndex], (*i)->GetType()), *i));

			regIndex++;
		}
	}

	return TreeNode::CreateNode((resultType == NODETYPE_UNDEFINED) ? NODE_SYSCALLVOID : NODE_SYSCALL, resultType, num, input);
}

function void AssignRegisterVariable(Variable* var)
{
	uint32_t reg = m_symFunc->AddRegister((var->GetType()->GetClass() == TYPE_FLOAT) ? FREG : IREG,
		ILParameter::ReduceType(var->GetType()));
	m_vars.registerVariables[var] = reg;

	// 64-bit variables take two adjacent registers
	if ((var->GetType()->GetWidth() == 8) && (var->GetType()->GetClass() != TYPE_FLOAT))
	{
		uint32_t highReg = m_symFunc->AddRegister(IREG, ILParameter::ReduceType(var->GetType()), 4);
		m_vars.highRegisterVariables[var] = highReg;
	}
}

function void AssignParameters()
{
	// Generate parameter offsets
	int64_t offset = 0;

	if ((m_func->GetName() == "_start") && (m_settings.unsafeStack))
		offset += UNSAFE_STACK_PIVOT;

	uint32_t intParamRegs[9] = {INTEGER_PARAM_0, INTEGER_PARAM_1, INTEGER_PARAM_2,
		INTEGER_PARAM_3, INTEGER_PARAM_4, INTEGER_PARAM_5, INTEGER_PARAM_6,
		INTEGER_PARAM_7, SYMREG_NONE};
	uint32_t floatParamRegs[9] = {FLOAT_PARAM_0, FLOAT_PARAM_1, FLOAT_PARAM_2,
		FLOAT_PARAM_3, FLOAT_PARAM_4, FLOAT_PARAM_5, FLOAT_PARAM_6,
		FLOAT_PARAM_7, SYMREG_NONE};
	uint32_t curIntParamReg = 0;
	uint32_t curFloatParamReg = 0;

	for (size_t i = 0; i < m_func->GetParameters().size(); i++)
	{
		// Find variable object for this parameter
		vector< Ref<Variable> >::const_iterator var = m_func->GetVariables().end();
		for (vector< Ref<Variable> >::const_iterator j = m_func->GetVariables().begin(); j != m_func->GetVariables().end(); j++)
		{
			if ((*j)->IsParameter() && ((*j)->GetParameterIndex() == i))
			{
				var = j;
				break;
			}
		}

		size_t paramSize = (m_func->GetParameters()[i].type->GetWidth() + 3) & (~3);

		// See if a register is used for this parameter
		uint32_t reg = SYMREG_NONE;
		uint32_t highReg = SYMREG_NONE;
		if (m_func->GetParameters()[i].type->IsFloat())
		{
			if (floatParamRegs[curFloatParamReg] != SYMREG_NONE)
			{
				uint32_t regClass = floatParamRegs[curFloatParamReg++];
				if (var != m_func->GetVariables().end())
					reg = m_symFunc->AddRegister(regClass, ILParameter::ReduceType((*var)->GetType()));
			}
		}
		else if (paramSize <= 4)
		{
			if (intParamRegs[curIntParamReg] != SYMREG_NONE)
			{
				uint32_t regClass = intParamRegs[curIntParamReg++];
				if (var != m_func->GetVariables().end())
					reg = m_symFunc->AddRegister(regClass, ILParameter::ReduceType((*var)->GetType()));
			}
		}
		else
		{
			if ((intParamRegs[curIntParamReg] != SYMREG_NONE) && (intParamRegs[curIntParamReg + 1] != SYMREG_NONE))
			{
				uint32_t regClass = intParamRegs[curIntParamReg++];
				uint32_t highRegClass = intParamRegs[curIntParamReg++];
				if (var != m_func->GetVariables().end())
				{
					reg = m_symFunc->AddRegister(regClass, ILParameter::ReduceType((*var)->GetType()));
					highReg = m_symFunc->AddRegister(highRegClass, ILParameter::ReduceType((*var)->GetType()), 4);
				}
			}
		}

		if (var == m_func->GetVariables().end())
		{
			// Variable not named, so it won't be referenced
			continue;
		}

		if (reg != SYMREG_NONE)
		{
			// If the variable has its address taken, it must be stored on the stack
			bool addressTaken = false;
			for (vector<ILBlock*>::const_iterator j = m_func->GetIL().begin(); j != m_func->GetIL().end(); j++)
			{
				for (vector<ILInstruction>::const_iterator k = (*j)->GetInstructions().begin();
					k != (*j)->GetInstructions().end(); k++)
				{
					if (k->operation != ILOP_ADDRESS_OF)
						continue;
					if (k->params[1].variable == *var)
					{
						addressTaken = true;
						break;
					}
				}
			}

			if (addressTaken)
			{
				// Must spill register to stack
				m_vars.stackVariables[*var] = m_symFunc->AddStackVar(0, false, (*var)->GetType()->GetWidth(),
					ILParameter::ReduceType((*var)->GetType()));

				IncomingParameterCopy copy;
				copy.var = *var;
				copy.incomingReg = reg;
				copy.incomingHighReg = highReg;
				copy.stackVar = m_vars.stackVariables[*var];
				m_paramCopy.push_back(copy);
				continue;
			}

			m_vars.registerVariables[*var] = reg;
			if (highReg != SYMREG_NONE)
				m_vars.highRegisterVariables[*var] = highReg;

			IncomingParameterCopy copy;
			copy.var = *var;
			copy.incomingReg = reg;
			copy.incomingHighReg = highReg;
			copy.stackVar = SYMREG_NONE;
			m_paramCopy.push_back(copy);
			continue;
		}

		// Allocate stack space for this parameter
		int64_t paramOffset = offset;

		if (m_settings.stackGrowsUp)
		{
			paramOffset = -paramOffset;
			paramOffset += 4 - paramSize;
		}

		m_vars.stackVariables[*var] = m_symFunc->AddStackVar(paramOffset, true, (*var)->GetType()->GetWidth(),
			ILParameter::ReduceType((*var)->GetType()));

		// Adjust offset for next parameter
		offset += (*var)->GetType()->GetWidth();
		if (offset & 3)
			offset += 4 - (offset & 3);
	}

	// Generate a variable to mark the start of additional paramaters
	int64_t paramOffset = offset;
	if (m_settings.stackGrowsUp)
		paramOffset = -paramOffset;
	m_varargStart = m_symFunc->AddStackVar(paramOffset, true, 0, ILTYPE_VOID);
}

function bool GenerateFunctionStart(SymInstrBlock* out)
{
	if ((m_func->GetName() == "_start") && m_settings.unsafeStack)
	{
		// This is the start function, and we can't assume we have a safe stack (the code may be
		// at or near the stack pointer), pivot the stack to make it safe
		uint32_t reg = TEMP_REGISTER(IREG);
		@LoadImm reg, UNSAFE_STACK_PIVOT;
		@Sub SYMREG_SP, SYMREG_SP, reg, 0;
	}

	// Generate function prologue
	if (m_framePointerEnabled)
	{
		@SaveCalleeSavedRegs;
		@Mov SYMREG_BP, SYMREG_SP;
	}
	else
	{
		@SaveCalleeSavedRegs;
	}

	// Generate a pseudo instruction to ensure the incoming parameters are defined
	vector<uint32_t> incomingRegs;
	for (vector<IncomingParameterCopy>::iterator j = m_paramCopy.begin(); j != m_paramCopy.end(); j++)
	{
		if (j->stackVar != SYMREG_NONE)
			continue;

		incomingRegs.push_back(j->incomingReg);
		if (j->var->GetType()->GetWidth() == 8)
			incomingRegs.push_back(j->incomingReg + 1);
	}

	if (incomingRegs.size() != 0)
		@RegParam incomingRegs;

	// Copy parameters into variables so that they can be spilled if needed
	for (vector<IncomingParameterCopy>::iterator j = m_paramCopy.begin(); j != m_paramCopy.end(); j++)
	{
		if (j->stackVar != SYMREG_NONE)
		{
			// Parameter was spilled onto stack
			if (j->var->GetType()->IsFloat())
			{
				switch (j->var->GetType()->GetWidth())
				{
				case 4:
					@StoreStackFS j->incomingReg, SYMREG_BP, j->stackVar, 0, TEMP_REGISTER(FREG);
					break;
				case 8:
					@StoreStackFD j->incomingReg, SYMREG_BP, j->stackVar, 0, TEMP_REGISTER(FREG);
					break;
				default:
					fprintf(stderr, "error: spilling invalid parameter\n");
					return false;
				}
			}
			else
			{
				switch (j->var->GetType()->GetWidth())
				{
				case 1:
					@StoreStack8 j->incomingReg, SYMREG_BP, j->stackVar, 0, TEMP_REGISTER(IREG);
					break;
				case 2:
					@StoreStack16 j->incomingReg, SYMREG_BP, j->stackVar, 0, TEMP_REGISTER(IREG);
					break;
				case 4:
					@StoreStack32 j->incomingReg, SYMREG_BP, j->stackVar, 0, TEMP_REGISTER(IREG);
					break;
				case 8:
					@StoreStack32 j->incomingReg, SYMREG_BP, j->stackVar, 0, TEMP_REGISTER(IREG);
					@StoreStack32 j->incomingHighReg, SYMREG_BP, j->stackVar, 4, TEMP_REGISTER(IREG);
					break;
				default:
					fprintf(stderr, "error: spilling invalid parameter\n");
					return false;
				}
			}
		}
		else if (j->var->GetType()->IsFloat())
		{
			// Parameter is in a floating point register
			uint32_t newReg = TEMP_REGISTER(FREG);
			@Fmov newReg, j->incomingReg;
			m_vars.registerVariables[j->var] = newReg;
		}
		else
		{
			// Parameter is in an integer register
			uint32_t newReg = TEMP_REGISTER(IREG);
			uint32_t newHighReg = SYMREG_NONE;
			if (j->var->GetType()->GetWidth() == 8)
				newHighReg = TEMP_REGISTER(IREG);

			@Mov newReg, j->incomingReg;
			if (newHighReg != SYMREG_NONE)
				@Mov newHighReg, j->incomingHighReg;
			m_vars.registerVariables[j->var] = newReg;
			if (newHighReg != SYMREG_NONE)
				m_vars.highRegisterVariables[j->var] = newHighReg;
		}
	}

	if (m_framePointerEnabled)
	{
		uint32_t temp = TEMP_REGISTER(IREG);
		if (m_settings.stackGrowsUp)
			@AddStack SYMREG_SP, SYMREG_SP, SYMVAR_FRAME_SIZE, 0, temp;
		else
			@SubStack SYMREG_SP, SYMREG_SP, SYMVAR_FRAME_SIZE, 0, temp;
	}

	return true;
}

arch function set<uint32_t> GetRegisterClassInterferences(uint32_t cls)
{
	set<uint32_t> result;
	uint32_t i;
	switch (cls)
	{
	case IREG:
		for (i = 0; i < 32; i++)
			result.insert(SYMREG_FPU_REG(i));
		break;
	case FREG:
		for (i = 0; i < 32; i++)
			result.insert(SYMREG_NATIVE_REG(i));
		break;
	default:
		break;
	}
	return result;
}

arch function bool DoesRegisterClassConflictWithSpecialRegisters(uint32_t cls)
{
	return false;
}

arch function void LayoutStackFrame()
{
	// Lay out stack variables
	int64_t offset = 0;
	for (size_t i = 0; i < m_stackVarOffsets.size(); i++)
	{
		if (m_stackVarIsParam[i])
			continue;

		int64_t align = 1;
		if (m_stackVarWidths[i] >= 4)
			align = 4;
		else if (m_stackVarWidths[i] >= 2)
			align = 2;

		if ((offset & (align - 1)) != 0)
			offset += align - (offset & (align - 1));

		m_stackVarOffsets[i] = offset;
		offset += m_stackVarWidths[i];
	}

	// Ensure stack stays aligned on native boundary
	if (offset & 3)
		offset += 4 - (offset & 3);

	m_stackFrameSize = offset;

	// Adjust variable offsets to be relative to the frame pointer (negative offsets)
	if (m_settings.stackGrowsUp)
	{
		for (size_t i = 0; i < m_stackVarOffsets.size(); i++)
		{
			if (!m_stackVarIsParam[i])
				m_stackVarOffsets[i] -= offset;
		}
	}

	for (size_t i = 0; i < m_stackVarOffsets.size(); i++)
	{
		if (m_stackVarIsParam[i])
			continue;
		if (m_settings.stackGrowsUp)
			m_stackVarOffsets[i] += m_stackFrameSize;
		else
			m_stackVarOffsets[i] -= m_stackFrameSize;
	}

	// Analyze callee saved registers
	uint32_t min = 29;
	set<uint32_t> fpu;
	int64_t adjust = 0;
	for (vector<uint32_t>::iterator i = m_clobberedCalleeSavedRegs.begin(); i != m_clobberedCalleeSavedRegs.end(); i++)
	{
		uint32_t reg = (*i) & 63;
		if (reg >= 32)
		{
			fpu.insert(reg & 31);
			adjust += 8;
		}
		else if (reg < min)
		{
			min = reg;
			if (m_settings.stackGrowsUp)
				adjust += 4;
		}
	}

	// Adjust parameter locations to account for callee saved registers
	if (!m_settings.stackGrowsUp)
		adjust += (31 - min) * 4;

	for (size_t i = 0; i < m_stackVarOffsets.size(); i++)
	{
		if (!m_stackVarIsParam[i])
			continue;

		if (m_settings.stackGrowsUp)
			m_stackVarOffsets[i] -= adjust;
		else
			m_stackVarOffsets[i] += adjust;
	}
}

arch function bool GenerateSpillLoad(uint32_t reg, uint32_t var, int64_t offset,
	ILParameterType type, vector<SymInstr*>& code)
{
	uint32_t temp = AddRegister(((type == ILTYPE_FLOAT) || (type == ILTYPE_DOUBLE)) ? FREG : IREG);
	switch (type)
	{
	case ILTYPE_INT8:
		@LoadStack8 reg, SYMREG_BP, var, offset, temp;
		break;
	case ILTYPE_INT16:
		@LoadStack16 reg, SYMREG_BP, var, offset, temp;
		break;
	case ILTYPE_INT32:
	case ILTYPE_INT64: // Uses two 32-bit regs
		@LoadStack32 reg, SYMREG_BP, var, offset, temp;
		break;
	case ILTYPE_FLOAT:
		@LoadStackFS reg, SYMREG_BP, var, offset, temp;
		break;
	case ILTYPE_DOUBLE:
		@LoadStackFD reg, SYMREG_BP, var, offset, temp;
		break;
	default:
		return false;
	}

	return true;
}

arch function bool GenerateSpillStore(uint32_t reg, uint32_t var, int64_t offset,
	ILParameterType type, vector<SymInstr*>& code)
{
	uint32_t temp = AddRegister(((type == ILTYPE_FLOAT) || (type == ILTYPE_DOUBLE)) ? FREG : IREG);
	switch (type)
	{
	case ILTYPE_INT8:
		@StoreStack8 reg, SYMREG_BP, var, offset, temp;
		break;
	case ILTYPE_INT16:
		@StoreStack16 reg, SYMREG_BP, var, offset, temp;
		break;
	case ILTYPE_INT32:
	case ILTYPE_INT64: // Uses two 32-bit regs
		@StoreStack32 reg, SYMREG_BP, var, offset, temp;
		break;
	case ILTYPE_FLOAT:
		@StoreStackFS reg, SYMREG_BP, var, offset, temp;
		break;
	case ILTYPE_DOUBLE:
		@StoreStackFD reg, SYMREG_BP, var, offset, temp;
		break;
	default:
		return false;
	}

	return true;
}

arch function void PrintRegister(uint32_t reg)
{
	if ((reg >= SYMREG_NATIVE_REG(0)) && (reg < SYMREG_NATIVE_REG(32)))
		fprintf(stderr, "r%d", reg & 31);
	else if ((reg >= SYMREG_FPU_REG(0)) && (reg < SYMREG_FPU_REG(32)))
		fprintf(stderr, "f%d", reg & 31);
	else
		SymInstrFunction::PrintRegister(reg);
}

